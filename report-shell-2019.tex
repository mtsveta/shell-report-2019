%% LyX 2.3.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english,sort&compress]{article}
\input{custom-packages}

\usepackage{wasysym} % for fullmoon, newmoon symbols

%\makeatother

% Definition of \maketitle
\makeatletter         
\def\@maketitle{
\begin{center}
{\bf \@title }\\[2ex] 
{\footnotesize \@author}\\[2ex] 
{\scriptsize \@date}\\[4ex]
\includegraphics[height=1cm]{figures/logos/shell.png}\qquad 
\includegraphics[height=1cm]{figures/logos/ethz.png}\qquad
\includegraphics[height=1cm]{figures/logos/geg.png}
\end{center}}
%\makeatother

\begin{document}
\title{Annual report 2019:\\
\emph{Reaktoro as the chemical reaction solver in Shell's reservoir simulator}}
\author{Allan M. M. Leal and Svetlana Kyas \\
{\scriptsize Institute of Geophysics, Department of Earth Sciences, ETH Z\"urich, Switzerland}}
\date{02.12.2019}

\maketitle

%---------------------------------------------------------------------------------------------------%
\begin{abstract}
The report in dedicated to describe the results obtained during the first year of the project 
``Reaktoro as the chemical reaction solver in Shell's reservoir simulator'. It is mainly focused 
on the first task of the project plan, i.e., ``Accelerating chemical kinetics in reactivate transport 
(RT) calculations''. Below, we summarise the main motivation of the this task. During reactivate 
transport modeling, 
the computational cost associated with chemical equilibrium and chemical kinetics speciation 
calculations can be 10–10'000 times higher than that of fluid flow and solute transport simulations. 
Such geochemical calculations must be performed in each mesh cell at every time step of the simulation, 
incurring high computing costs. To radically reduce these, we consider a new \emph{on-demand machine 
learning strategy} (ODML) (also referred as \emph{smart algorithm}) that, during reactive transport 
simulations, enables the chemical speciation to be quickly and accurately predicted using stored 
results of previous chemical equilibrium calculations performed within the simulation session. 
We demonstrate the applicability and utility of this algorithm in a reactive transport modeling 
example, where it yields a calculation speedup of one-two orders of magnitude. The implementation 
and numerical tests are carried out in Reaktoro, a unified, open-source framework for modeling 
chemically reactive systems. Further research plans and ideas to improve considered algorithm are 
also summarized.
\end{abstract}

\section{Introduction}

%---------------------------------------------------------------------------------------------------%
In reactive transport simulations, coupled chemical and physical processes are modeled to understand 
phenomena that involve the transport of chemical species (i.e. reactants) and chemical reactions. 
Examples of chemical processes are reactions between species in an aqueous fluid leading to 
precipitation of solid minerals, or their reaction with existing rock minerals causing mineral 
dissolution. Examples of physical processes are the advection of chemical species in a fluid that flows 
with a certain velocity, or the diffusion of those fluid species as a result of the concentration 
gradient across the medium. Because of the various processes combined into a reactive transport model, 
the resulting computer simulations are usually time-consuming.

%---------------------------------------------------------------------------------------------------%
Often, the relatively long computing time of reactive transport simulations can be largely attributed 
to the need of performing millions to billions of chemical reaction calculations, in particular, 
\emph{chemical kinetics} and\slash or \emph{equilibrium speciation calculations} performed in every 
mesh cell during every time step of the simulation. These chemical reaction calculations are 
computationally expensive because they involve iterative algorithms to solve systems of non-linear 
algebraic (SnLAE) and\slash or ordinary differential equations (ODEs) \citep{Leal2017}. As a result, 
they trigger repeated evaluations of thermodynamic properties, such as activity\slash fugacity 
coefficients (sometimes using computationally demanding models such as \citet{Pitzer1973} for aqueous 
phases and \citet{Peng1976} for gaseous/liquid phases).

%---------------------------------------------------------------------------------------------------%
Thus, speeding up reactive transport modeling by a significant factor may only be accomplished by 
first accelerating chemical reaction calculations in general. Advancing chemical equilibrium speciation 
calculations is essential when employing a \emph{partial local chemical equilibrium assumption} 
\citep{Ramshaw1980,Ramshaw1981,Ramshaw1985,Ramshaw1995,Lichtner1985,Steefel1994,Steefel1996}.
This assumes that the species that are reacting at relatively high rates (typically aqueous or gaseous 
species) are in a state of continual chemical equilibrium in each mesh cell. In contrast, the species 
reacting at slow to moderate rates (typically minerals) do so according to kinetic rate laws and, 
hence, are not in equilibrium with the rest of the system. Thus, accelerating those millions to 
billions of chemical calculations over the course of a massive numerical reactive transport simulation 
is essential when using fine-resolution meshes, large three-dimensional domains, and\slash or long 
simulation times at fine temporal resolution.

%---------------------------------------------------------------------------------------------------%
Major advances in developing fast, accurate, and robust methods for chemical equilibrium calculations, 
in particular, have been achieved over the past decades. These are either based on 
\emph{Gibbs energy minimization} (GEM) or \emph{law of mass action} (LMA) formulations 
\citep{White1958,Smith1980,Smith1982,Alberty1992b,Crerar1975,DeCapitani1987,Eriksson1989,Ghiorso1994,
Gordon1971,Gordon1994a,Gordon1996,Harvey2013,Harvie1987,Karpov1997,Karpov2001,Karpov2002,Koukkari2011a,
Kulik2013,Leal2013,Leal2014,Leal2016a,Leal2016c,Leal2017,Morel1972,Neron2012,Nordstrom1979,
Trangenstein1986,VanZeggeren1970,Vonka1995,Wolery1975,Zeleznik1960}.
%
However, even if one could devise a hypothetical algorithm that would always converge in a single 
iteration, instead of the typical few to dozens of iterations, the computational cost of chemical 
equilibrium calculations could still be dominant in a reactive transport simulation. This is the case, 
as during this single iteration, expensive thermodynamic models would still have to be evaluated and 
matrix equations be solved, when using a Newton-based GEM or LMA algorithm. In view of this, a 
substantial acceleration of these calculations can be achieved if those costly operations
can be bypassed whenever possible. Similarly, advanced methods for solving system of ODEs has been 
developed during couple of last decades { \color{red} TODO: add citation to classic works \cite{}}. 
However, we aim to develop such an approach that sidesteps costly numerical integration of the system 
that governs the evolution of kinetics species within considered transport step.

\begin{figure}[!t]
	\centering
	\subfloat[]{
	\includegraphics[height=6cm]{figures/intro/similar-equilibirum}
	\label{fig:similar-equilibrium}}
	\quad
	\subfloat[]{
	\includegraphics[height=6cm]{figures/intro/similar-kinetics}
	\label{fig:similar-kinetics}}
	\caption{Example of similar chemical speciations encountered in chemical equilibrium and kinetics.}
	\label{fig:similar-equilibrium-kinetics}
\end{figure}

%---------------------------------------------------------------------------------------------------%
During a single time step of a reactive transport simulation, chemical kinetics and equilibrium
calculations are needed in all mesh cells. Often, many of these calculations are similar to previously 
performed ones, either within the same time-step and\slash or mesh cell or at different points in 
space and\slash or time (see Figure \ref{fig:similar-equilibrium-kinetics}). We assume two chemical 
equilibrium problems to be similar when their input conditions are sufficiently close (i.e., similar 
temperature, pressure, amounts of chemical elements, and the electric charge of each phase, containing 
electrically charged species \citep{Smith1982}). At the same time, these chemical equilibrium 
calculations are hardly identical so that we cannot simply assume a previously computed chemical 
speciation as the exact result of the new calculation. Interpolating is also not an appropriate
approach, as it can violate the \emph{mass conservation} of elements (i.e., there is a deviation 
between the input element amounts and the amounts of elements calculated from the interpolated species 
amounts). 

%---------------------------------------------------------------------------------------------------%
The main principle of the \emph{algorithm}, suggested here, is precisely to \emph{avoid} as much as 
possible full and expensive chemical speciation calculations during the reactive transport simulation. 
That is why it is often referred as \emph{smart chemical equilibrium algorithm}. By using 
\emph{sensitivity derivatives} of previously computed chemical equilibrium states, we can quickly 
and accurately estimate the new equilibrium state (chemical speciation) under similar input conditions
(see Figure \ref{fig:similar-equilibrium}). These derivatives provide an insight on how sensitive
the computed species amounts at a certain equilibrium state are with respect to infinitesimally small 
changes in temperature, pressure, and amounts of chemical elements. Thus, multiplying these sensitivity 
derivatives by the respective differences in input conditions (e.g., differences in temperature
or the amount of a particular element), we can predict the variation in the output. For example, we 
can estimate how much the species amounts would change by increasing temperature by 1~°C, by adding 
1~mmol of HCl into the system (which is equivalent to adding 1~mmol of elements H and Cl), or by 
combining these with other input changes. We remark that the use of sensitivity derivatives to estimate 
the solution of an equilibrium problem is inherently \emph{mass conservative}, since they are being 
computed along the derivation of chemical equilibrium equations (with equations of element mass 
conservation included).

%---------------------------------------------------------------------------------------------------%
If kinetically controlled species are considered, one can find similarities in their initial 
states at each transport step. Figure \ref{fig:similar-kinetics} illustrated possible perturbations 
of fluid/rock compositions in mess cells discretising two-dimensional reservoir. \emph{Smart chemical 
kinetics algorithm} will perform numerical integration of the system of kinetic species only in 
firstly evaluated/uniquely distinguished initial states (marked with empty circles in Figure 
\ref{fig:similar-kinetics}), recovering simultaneously additional information about their sensitivities 
with respect to (w.r.t.) infinitesimal changes in the initial condition. In the rest of the subsequently 
encountered cells, we attempt to make \emph{smart prediction} of the possible kinetic speciation at the 
end of the transport step.

\subsubsection*{Related Work}

Increasing the speed of chemical speciation calculations, whether it is equilibrium and\slash or 
kinetics, is an active research topic. The majority of the existing methodologies are based on the use 
of \emph{surrogate models} and\slash or \emph{statistically based machine learning} schemes, which use 
a computationally cheaper model (e.g., linearization, parameterization, convolutional neural network) 
to approximate a complex nonlinear behavior.

%---------------------------------------------------------------------------------------------------%
In combustion chemistry, the pioneering work of \citet{Pope1997} in accelerating \emph{chemical 
kinetics calculations} considered approximations of chemical kinetics paths using multiple linear 
regressions, employing \emph{unstructured adaptive} \emph{storage/extraction techniques} along 
the simulation process. This approach is referred to in the literature as the \emph{in-situ adaptive 
tabulation} (ISAT) algorithm. The ISAT approximation idea was later extended to \emph{nonlinear
model predictive control} (NMPC) in \citep{HedengrenEdgar2008}. ISAT can be regarded as an alternative 
to artificial neural networks, as it does not require any preliminary training to simulate the 
behavior of the model. Instead, the it rearranges the model by the training on new data \emph{on the 
fly}, as simulations proceed. The ISAT algorithm scales quadratically with increased dimension, 
approximates functions with discontinuities, and provides explicit bounds on approximation errors. 
Recent improvements of this approach as well as its extension to reactive transport problem can be 
found in \cite{Singer2004, Singer2006, Lu2007, Pope2009, Lu2009}.
%
A series of parallel chemistry acceleration algorithms using different distribution strategies for
simulation of unsteady, compressible, reactive flows, based on the ISAT technique, was implemented in 
the software \texttt{\href{https://tcg.mae.cornell.edu/x2f_mpi/}{${\rm x2f_mpi}$}} \cite{x2fmpi2006} and 
studied for the numerical simulations of a two-dimensional gaseous detonation wave propagation process 
in \citet{Dong2007, Dong2009, WuDongLi2018}. 

\begin{comment}
The main difference of algorithm used in the current work from the ISAT method is that it first aims 
to accelerated not only kinetic part of chemical modeling but also equilibrium speciation calculations. 
They are triggered during the evaluation of the reaction rates as kinetic paths are being evaluated, as 
well as after kinetic species has been integrated to update the equilibrium speciation. Moreover, 
instead of using approximate derivatives, \texttt{Reaktoro} uses automatic differentiation for their 
exact evaluation. This makes predictions of the new chemical equilibrium speciations more exact. Finally, 
unlike purely mathematical approach of controlling the error by keeping track of the so-called 
``confidence'' region, we use an approach that accounts for chemical properties (such as activities or 
potentials) to decide on the accuracy/acceptance of the predicted state.
\end{comment}

%---------------------------------------------------------------------------------------------------%
In the presentation of the \emph{on-demand machine learning} (ODML) algorithm given later, 
one can observe similarities with ISAT on the approach for speeding up the output of non-linear 
problems with similar inputs. It must be noted, however, that ODML 
%
\begin{enumerate}[wide, labelwidth=!, labelindent=0pt]
\item[\emph{(i)}] aims to be a more \textbf{general-purpose acceleration algorithm} (instead of 
being applied exclusively to chemical kinetics problems),
%
\item[\emph{(ii)}] uses \textbf{higher-order sensitivity derivatives} for improved predictive 
accuracy, significant reduced number of on-demand training operations, and superior error analysis, 
%
\item[\emph{(iii)}] provides the capability for \textbf{more flexible error controls} (rather than
a purely geometric one based on hyper-ellipsoids) that may consider chemical\slash physical\slash 
engineering insights on the acceptance decision, and, finally,
%
\item[\emph{(iv)}] uses \textbf{alternative search operations} that do not rely exclusively on 
NN search, which is prone to fail for high-dimensional input spaces (commonly-known in 
the statistical and machine learning literature as the \emph{curse of dimensionality}). 
\end{enumerate}
%
A dedicated C++ library project for ODML is envisioned, in which the exact higher-order sensitivity
derivatives mentioned previously are calculated using \texttt{\href{http://autodiff.github.io}{autodiff}}
(\citealt{autodiff}), a modern and fast C++ library for higher-order automatic differentiation 
computations, whose on-going development is specifically carried out towards achieving the planned 
algorithm's goals outlined above.

%---------------------------------------------------------------------------------------------------%
In addition to the ISAT approach, several alternative storage-based approaches have been suggested in 
the past for accelerating chemical kinetics calculations, including polynomial fits \citet{Turanyi1994}, 
artificial neural networks (see, e.g., \citet{ChristoMasriNebot1996,Blascoetall1998}), and piece-wise 
reusable implementation of solution mapping (PRISM) by \citet{TonseMoriartyBrownFrenklach2013}. The 
common property of these approaches is the a priori creation of the approximation model (whether it 
is a skeleton model or a neural network), which usually requires extra effort to then evaluate a 
simplified model that accelerates subsequent calculations. The PRISM method is similar to the in-situ 
approach, except that the stored data entries are not output values and corresponding sensitivity 
derivatives, but rather the set of polynomials, covering a region of chemical composition space. 
The observed acceleration for these methods is about a factor of 10-60.

%---------------------------------------------------------------------------------------------------%
The work of \citet{Jatnieks2016}, on the use of a surrogate model for fast speciation calculations, 
is another initiative to accelerate chemical equilibrium calculations during reactive transport 
modeling. The construction of this surrogate model required a training stage in advance of the 
simulation of interest, during which many random input conditions are used in a speciation solver, 
such as PHREEQC \citep{Parkhurst2013}, and the resultant outputs collected for statistics-based 
learning. During their numerical experiment,~32~different statistical and machine learning methods
were tried to identify the potentially best one. For a specific reactive transport modeling problem, 
\citet{Jatnieks2016} collected all possible input-output combinations in speciation calculations, and 
from these, 7880 input-output samples, representing 80\% of the total known input-output relationships, 
were used for training the statistical model. The various constructed surrogate models were subsequently 
used in the reactive transport simulation. Because these surrogate models relied on statistical methods, 
mass conservation was often not accurate during their machine learning computations (i.e., the amounts 
of chemical elements in the estimated-output species amounts did not correspond accurately to the 
values given in the input). 

The work \cite{Laloy2019} presents a comparison of several approaches 
(Gaussian processes (GP), polynomial chaos expansion (PCE) and deep neural networks (DNNs)), which are 
used to emulate CPU-intensive reactive transport models. However, considered methods are subjected 
to uncertainties propagation and, as result, deteriorating accuracy. For relatively simple problems 
DNNs performed the best (even having relatively small training sets), providing the most accurate 
representation of results. However, the DNN approach leads to the worst solution of the considered 
synthetic inverse problem due to the small but rather complicated deterministic noise that affects 
the DNN-based predictions. Also, for more complicated problems DNN produces quite disperse outputs, 
which only confirms the difficulty of finding emulator able to replace the entire reactive transport 
process with all its complex behaviours and possible outcomes. The approach proposed in our work 
focuses only of speeding up the chemical part of the entire simulation, which narrows down the amount 
of physical effects influencing the input space and, as results, allows to find more similarities 
triggering more smart predictions.
%
Moreover, unlike the ``black-box'' representation of the complex original model used by methods in 
\cite{Laloy2019}, our approach ``remembers'' the most crucial properties of the chemical system under 
consideration (such as mass balance equation, sensitivity derivatives, ect.), allowing to maintain 
the requested accuracy of simulations' results.

%---------------------------------------------------------------------------------------------------%
The \emph{on-demand learning approach} developed here exhibits several advantages over conventional 
statistics- or neural network- based machine learning methods. Firstly, the use of \emph{sensitivity 
derivatives} of the calculated equilibrium states results in a method that better reflects the behavior 
of chemical systems and how they react to subsequent changes in input equilibrium conditions. Secondly, 
the use of these sensitivity derivatives permits predicting new equilibrium states \emph{without loss 
of accuracy and confidence}. Thirdly, the proposed method requires \emph{no a priori statistical 
training} before it can be applied in a reactive transport simulation. Its on-demand machine learning 
characteristics enables spontaneous learning of only what is needed to be calculated anew during 
a reactive transport simulation to keep new predictions accurate enough. Note that, when using 
a conventional chemical equilibrium calculation approach, these computations are needed anyway. 

%---------------------------------------------------------------------------------------------------%
Furthermore, discussed here on-demand learning strategy is not only simpler from an end-user point 
of view (as no a priori training stage needs to be performed), but also likely faster. It will, 
in general, require saving far fewer input conditions and computed chemical speciations than any 
statistical approach, which can only get the more accurate the more it trains in advance, and where 
the amount of useful training calculations is unknown. This lack of knowledge typically leads to 
the calculation of many more chemical reaction results than what may ever be needed during the actual 
simulation, with a risk that actually required calculations may not have been part of the a priori 
training set at all. This is akin to going to school to learn all sorts of things, most of which are 
never needed later on for a specific job at hand. 

%---------------------------------------------------------------------------------------------------%
Finally, the smart chemical equilibrium algorithm produces output speciations that \emph{always 
satisfy conservation conditions} for chemical elements and electric charge, as these constraints are 
incorporated into the calculation of the sensitivity derivatives (see \citet{Leal2017}). This, in 
particular, distinguishes the discussed method from the statistics-based machine learning methods, 
which can loose precision or fail in this respect.

%---------------------------------------------------------------------------------------------------%
\subsubsection*{Organization}

This report is organized as follows:
\begin{description}
\item [{Section~\ref{sec:Definitions-and-Notation}}] introduces definitions and the notation needed 
to describe the algorithm.
\item [{Section~\ref{sec:Method}}] formulates the smart chemical equilibrium algorithm with details 
regarding the learning and prediction operations.
\item [{Section~\ref{sec:Results}}] demonstrates the performance and accuracy of a reactive transport 
simulation, using the smart chemical equilibrium / kinetics algorithms. It consists of three part 
with results corresponding to three major stages of development of smart algorithm. The first tests
of the algorithm were focused on studying its performance in RT model with all the species controlled
by equilibrium and with Pitzer activity model used (see Subsection \ref{subsec:part-1}). Subsection
\ref{subsec:part-2} is dedicated to describe the performance of smart approach on the chemical system 
with kinetically controlled species. Finally, Subsection \ref{subsec:part-3} highlights results of 
RT simulations obtained after coupling Reaktoro to the Firedrake, an automated system for the solution 
of partial differential equations using the finite element method (FEM) \cite{Rathgeber2016}. 
\item [{Section~\ref{sec:Discussion-and-Conclusions}}] discusses implications and conclusions of 
this report together with a road-map for further research efforts in this direction.
\end{description}

%---------------------------------------------------------------------------------------------------%
\section{Definitions and Notation\label{sec:Definitions-and-Notation}}

Considered throughout the paper, a \emph{chemical system} is a collection of \emph{chemical species} 
composed of one or more \emph{elements} and distributed among one or more \emph{phases}. The species 
can be substances such as aqueous ions (e.g., Na$^{+}$(aq), Cl$^{-}$(aq), HCO$_{3}^{-}$(aq)), neutral 
aqueous species (e.g., SiO2(aq), CO$_{2}$(aq), H$_{2}$O(l)), gases (e.g., CO$_{2}$(g), CH$_{4}$(g), 
N$_{2}$(g)), pure condensed phases (e.g., CaCO$_{3}$(s, calcite), SiO$_{2}$(s, quartz), 
Al$_{2}$Si$_{2}$O$_{5}$(OH)$_{4}$(s, kaolinite)), etc. Each phase (e.g., aqueous, gaseous, liquid, 
solid solutions, a pure mineral, plasma, etc.), having homogeneous properties within its boundaries 
is composed of one or more different chemical species (components, end members). Multi-component 
phases are also called \emph{solutions}, where components are mixed within the same structure.  
The elements (independent components) are \emph{chemical elements} (e.g., H, O, C, Na, Cl, Ca, Si) 
and \emph{electrical charge} (Z), but can also be linear combinations of these, commonly known as 
\emph{primary species} (e.g., H$^{+}$(aq), H$_{2}$O(l), CO$_{2}$(aq)).

A chemical system can exist at infinitely many \emph{chemical states}. A chemical state is defined 
here as the quadruplet $(T, P, n, b)$, where $T$ is temperature, $P$ is pressure,  
$n=(n_{1},\ldots,n_{\mathrm{N}})\in\mathbb{R}^{{\rm N}}$ is the vector of species amounts 
(speciation), with $n_{i}$ denoting the amount of the $i$th species (in moles) and N the number of 
species, and $b=(b_{1},\ldots,b_{\mathrm{E}})\in\mathbb{R}^{{\rm E}}$ is the vector of element 
amounts with $b_{j}$ being the amount of the $j$th element (in moles) and ${\rm E}$ the number of 
elements. In general, $b$ is related to $n$ via the following mass conservation equation:
%
\begin{equation}
An=b,
\label{eq:mass-balance}
\end{equation}
%
where $A$ is the \emph{formula matrix} of the chemical system \citep{Smith1982} (whose dimensions 
are $\mathrm{E}\times\mathrm{N}$), with $A_{ji}$ denoting the coefficient of the $j$th element in 
the $i$th species.

In order to consider system with kinetically controlled species, we assume the partition of the 
speciation to equilibrium and the kinetic species with corresponding amounts 
$n_{e} \in \mathbb{R}^{N_e}$ and $n_{k} \in \mathbb{R}^{N_k} $ and bulk compositions 
$b_{e}, b_{k} \in \mathbb{R}^{E}$. Then, the total amount of chemical species is presented as 
\[
n=\begin{bmatrix}n_{e}\\n_{k}\end{bmatrix} \in \mathbb{R}^{N}
\]
with the formula matrix $A=\begin{bmatrix}A_{e}\,A_{k}\end{bmatrix}$ composed of 
matrices of the equilibrium and kinetic species $A_{e}$ and $A_{k}$, respectively. 

%---------------------------------------------------------------------------------------------------%
\section{Method\label{sec:Method}}

Let the dependence of $n_{e}$ from $b_{e}$ is prescribed by the abstract chemical equilibrium function 
%
\begin{equation}
n_{e}=\varphi(b_{e}),\varphi:\mathbb{R}^{E}\rightarrow\mathbb{R}^{N},
\label{eq:equilibrium-func}
\end{equation}
%
that encapsulates the specific algorithmic steps to solve the fundamental Gibbs energy minimization 
problem
%
\[
\varphi(b_{e}):={\rm argmin}_{n_{e}} G_{e} = n_{e}^{T} \mu_{e}
\quad\mbox{s.t.}\quad
\begin{cases}
A_{e} \, n_{e} & =b_{e}\\
n_{e} & \geq0
\end{cases}.
\label{eq:gem-problem}
\]
%
The \emph{chemical potential} of the $i$th species $\mu_{e, i}=\mu_{e, i}(T,P,n_e)$ is defined as:
%
\begin{equation}
\mu_{e, i}=\mu_{e, i}^{\circ}+RT\ln a_{e, i},
\end{equation}
%
with $R$ denoting the universal gas constant, $\mu_{e, i}^{\circ}=\mu_{e, i}^{\circ}(T,P)$ the 
\emph{standard chemical potential} of the $i$th species, and $a_{e, i}=a_{e, i}(T,P,n_e)$ the 
\emph{activity} of the $i$th species. Methods for solving chemical equilibrium problem using either 
Gibbs energy minimization (GEM) or law of mass action (LMA) methods are addressed in 
Appendix~\ref{subsec:Chemical-equilibrium-equations} or with more detail in 
\citet{Leal2016a,Leal2016c,Leal2017} and references therein.

%---------------------------------------------------------------------------------------------------%
The amounts of the kinetic species $n_{k}$ are governed by the system of ordinary differential 
equations
%
\begin{equation}
\begin{array}{r@{$\;$}l@{$\quad$}l}
	\frac{dn_{k}}{dt} & = r(n_{k}) + q_{k} & t>0,\\
                n_{k} & = n_{k}^{\circ}    & t=0,
\end{array}
\label{eq:kinetics}
\end{equation}
%
%---------------------------------------------------------------------------------------------------%
where $r$ are the \emph{rates} of the kinetically controlled reactions,  $q_{k}$ denotes 
the \emph{vector of inflow/outflow} rates of the kinetic species, and $n_{k}^{\circ}$ 
the \emph{initial amounts} of the kinetic species. For more detailed derivation of 
the differential-algebraic system that governs \emph{chemical state of a system} we refer to 
Appendix~\ref{subsec:Chemical-kinetics-equations} or with more detail in 
\citet{Leal2015,Leal2017} and references therein.

\subsection{First-Order Taylor Approximation\label{subsec:First-order-Taylor-approximation}}

%---------------------------------------------------------------------------------------------------%
Assume that a chemical equilibrium calculation has been performed previously with input conditions
$(T^{\star},P^{\star},b^{\star})$, and a new one needs to be performed with $(T,P,b)$ instead. 
Rather than computing $n_e=\varphi(T,P,b_e)$, using the computationally expensive equilibrium 
function $\varphi$ (cf. \ref{eq:equilibrium-func}), we first try estimating $\bar{n}_e$ with a 
\emph{first-order Taylor approximation}:
%
\begin{equation}
\bar{n} = 
n^{\star}+\frac{\partial\varphi}{\partial T}^{\star}(T-T^{\star})
+\frac{\partial\varphi}{\partial P}^{\star}(P-P^{\star})
+\frac{\partial\varphi}{\partial b}^{\star}(b-b^{\star}),
\label{eq:smart-estimate}
\end{equation}
%
where $(\partial\varphi/\partial T)^{\star}$, $(\partial\varphi/\partial P)^{\star}$, and 
$(\partial\varphi/\partial b)^{\star}$ are \emph{sensitivity derivatives} of the reference chemical 
equilibrium state, which can be equivalently written as $(\partial n/\partial T)^{\star}$, 
$(\partial n/\partial P)^{\star}$, and $(\partial n/\partial b)^{\star}$, respectively. If computed 
together with the full speciation vector $n$, these sensitivity derivatives will allow us to estimate 
how the species amounts in an equilibrium state change when small perturbations are applied to 
temperature, pressure, and\slash or amounts of elements, and, therefore, quickly and accurately 
estimate entirely new states in the vicinity of some previous and fully calculated chemical 
equilibrium state.

%---------------------------------------------------------------------------------------------------%
In case, of kinetically controlled species similar logic can be applied. We use the sensitivities 
of species $n_k$ w.r.t. the small perturbation in initial condition $n_k^\circ$ defined as
%
\[
\frac{\partial n_k}{\partial n_k^\circ}. 
\]
%
%---------------------------------------------------------------------------------------------------%
Let $\Big(\tfrac{\partial n_k}{\partial n_k^\circ}\Big)^\star$ be stored along with $n^\star_k$ 
as a result of numerical integration of the system \eqref{eq:kinetics} with initial state 
$\big(n^\circ_k\big)^\star$. Then, evaluating new chemical state the initial condition $n^\circ_k$, 
the kinetic species can be approximated as follow:
%
\begin{equation}
\bar{n}_k 
= n^\star_k + \delta n_k
= n^\star_k + \Big(\tfrac{\partial n_k}{\partial n_k^\circ} \Big)^\star \, 
\big(n^\circ_k - (n^\circ_k)^\star \big)
\label{eq:smart-estimate-kinetics}
\end{equation}
%
If $\bar{n}_k$ is accurate enough, the complex numerical integration of the system 
\eqref{eq:kinetics} is replaced by matrix-vector multiplication formula 
\eqref{eq:smart-estimate-kinetics}. 

\begin{comment}
% more detailed explanation

%---------------------------------------------------------------------------------------------------%
In case, of kinetically controlled species similar logic can be applied. We introduce the property 
that measures how sensitive species $n_k$ w.r.t. the choice of initial condition $n_k^\circ$. It is
called \emph{sensitivity} and defined as
%
\[
s(t) := \frac{\partial n_k}{\partial n_k^\circ}(t). 
\]
%
%---------------------------------------------------------------------------------------------------%
Let $s^\star = \Big(\tfrac{\partial n_k}{\partial n_k^\circ}\Big)^\star$ be evaluated and stored 
along with $n^\star_k$ after numerical integration has been performed with initial state 
$\big(n^\circ_k\big)^\star$. Then, provided with a new initial condition for the kinetic species 
$n^\circ_k$, $\bar{n}_k$ can be approximated as follow:
%
\begin{equation}
\bar{n}_k 
= n^\star_k + \delta n_k
= n^\star_k + s^\star \, \delta n^\circ_k 
= n^\star_k + \Big(\tfrac{\partial n_k}{\partial n_k^\circ} \Big)^\star \, 
\big(n^\circ_k - (n^\circ_k)^\star \big)
\label{eq:smart-estimate-kinetics}
\end{equation}
%
Analogously to Eq. \ref{eq:smart-estimate}, the complex numerical integration of the system 
\eqref{eq:kinetics} is replaced by matrix-vector multiplication formula 
\eqref{eq:smart-estimate-kinetics}. Here, sensitivity is a matrix $s\in\mathbb{R}^{N\times N}$ that 
satisfies the following system of ODEs
% 
\begin{align*}
\frac{d s}{dt} & = J_r (n) \, s & t>0,\\
             s & = I            & t=0,
\end{align*}
%
where ${J}_{r}$ is a Jacobian of $r(n_k)$, and ${I} \in \mathbb{R}^{N \times N}$ is the identity 
matrix.
\end{comment}

%---------------------------------------------------------------------------------------------------%
\subsection{Nearest Neighbor Search\label{subsec:Nearest-Neighbor-Search}}

Let 
%
\begin{equation}
\mathcal{I}_e =\left\{ (T^{i},P^{i},b_e^{i})\right\}_{i=1}^{{\rm I}} 
\qquad \mbox{and} \qquad 
\mathcal{I}_k =\left\{ (n^{\circ}_k)^j \right\}_{j=1}^{{\rm J}}.
\end{equation}
%
represent the sets of input conditions for the chemical equilibrium and kinetics problems that 
have been fully solved (i.e., using the chemical equilibrium function $\varphi$ or system of ODEs 
\eqref{eq:kinetics}).
%
%---------------------------------------------------------------------------------------------------%
Furthermore, let 
%
\begin{equation}
d^{i}_e = \left[
\left(T-T^{i}\right)^{2} 
+\left(P-P^{i}\right)^{2}
+\sum_{l=1}^{{\rm E}}\left(b_{l}-b_{l}^{i}\right)^{2}\right]^{\frac{1}{2}} 
\qquad \mbox{and} \qquad 
d^{j}_k = \left[ \sum_{m=1}^{{\rm N_k}} 
\left((n^\circ_{k, m})^{\,j} - n^\circ_{k, m}\right)^2 \right]^{\frac{1}{2}} 
\end{equation}
%
denote the Euclidean distances either from $(T, P, b_e)^i$ to $(T,P,b)$ or from 
$(n^\circ_{k})^{\,j}$ to $n^\circ_{k}$. In $d^{i}_e$, the input condition of the $i$th fully 
solved problem and the given input condition for the new equilibrium calculation are compared, 
whereas $d^{j}_k$ measures the distance between the initial condition of $j$th fully integrated 
problem and the initial condition of new kinetic problem.

%---------------------------------------------------------------------------------------------------%
For the first-order Taylor expansion presented in Eq.~(\ref{eq:smart-estimate}) or 
Eq.~(\ref{eq:smart-estimate-kinetics}), a potentially suitable candidate for $(T,P,b_e)^{\star}$ or 
$(n^\circ_k)^\star$ is the \emph{nearest neighbor} (NN) of $(T,P,b)$ or $n^\circ_k$ among all inputs 
in $\mathcal{I}_e$ or $\mathcal{I}_k$ (i.e., saved input with the shortest Euclidean distance to 
$(T,P,b)$ or $n^\circ_k$). Note that other norms and strategies can be used to define the most 
optimal reference element for the prediction.

Plenty of algorithms have been reported in the literature to conduct a fast multi-dimensional NN 
search. The use of \emph{kd-tree data structures} to store the inputs, for example, may permit us to
obtain an algorithm complexity $\log_{2}(\mathrm{K})$, where $\mathrm{K}$ is the number of entries 
in the set. This implies that in a set with 1024~entries, only about 10 distance comparisons are 
performed. This contrasts with a linear search algorithm, with complexity $O(\mathrm{K})$,
which would instead require 1024 corresponding evaluations and comparisons.

%---------------------------------------------------------------------------------------------------%
The above algorithms, however, may behave very differently, depending on the number and dimension 
of the input vectors collected. Tree data structures have a more sparse memory pattern than 
contiguous memory data structures, such as arrays\slash vectors. The portions of the data for the 
latter can be cached by the CPU, enabling processing them at much faster rates. This implies that 
for sufficiently small data-sets (e.g, with dozens to perhaps a few hundred entries), tree-based 
search algorithms could be sub-optimal. Under these circumstances, a linear search algorithm, 
conjugated with contiguous memory data structures, can be more efficient.

%---------------------------------------------------------------------------------------------------%
In the first version of the algorithm implementation, we have relied solely on a linear search
algorithm, which worked well in the acceleration of the reactive transport problem (assuming all the 
species are controlled by equilibrium) shown in Section~\ref{sec:Results}. Complementing
the computer implementation of the smart chemical equilibrium algorithm
with kd-tree/locality-sensitive hashing search algorithms is ongoing work.

\subsection{Acceptance Test}

%---------------------------------------------------------------------------------------------------%
Once a predicted chemical equilibrium state is calculated, it must be tested for acceptance. Due 
to the usage of the first-order Taylor approximation, we need to ensure that the new estimated 
chemical state is not ``too far'' from the previous fully calculated one, used as a reference point. 
This could be done naively by checking how much the species amounts have changed from one state to 
another, using the following test condition for all species:
%
\begin{equation}
|\bar{n}_{i}-n_{i}^{\star}| \leq \epsilon_{\rm rel} |n_{i}^{\star}| + \epsilon_{{\rm abs}} 
\qquad(i=1,\ldots,{\rm N}_e).
\label{eq:eq:acceptance-test-n}
\end{equation}
%
Eq.~(\ref{eq:eq:acceptance-test-n}) controls how much absolute and relative changes in the new
estimated species amounts, $\bar{n}_{i}$, can be tolerated for given absolute and relative tolerance 
parameters $\epsilon_{{\rm abs}}$ and $\epsilon_{{\rm rel}}$, respectively.

%---------------------------------------------------------------------------------------------------%
The major drawback of the tolerance test in Eq.~(\ref{eq:eq:acceptance-test-n}) is that it does not 
reflect the thermodynamic \emph{behavior of stable species and phases}. Consider, for instance, a 
chemical system with two stable phases: an aqueous solution saturated with respect to a pure mineral 
phase. Adding more of that mineral composition to the system will not alter the composition of the
fluid, but just increase the current solid phase amount. Under such conditions, the acceptance test, 
based on species amounts, would fail even though the estimated chemical equilibrium state, using 
first-order sensitivity derivatives, would be exact. This happens, because  the amount of the mineral 
increases linearly, while the amount of each aqueous species remains constant.

%---------------------------------------------------------------------------------------------------%
However, in the example above, assuming that the perturbation of the system is introduced only by 
adding the mineral phase stoichiometry to the $b_e$ vector, without changing the temperature and 
pressure, there is one thermodynamic quantity that would remain constant: $\mu_{i}$, the chemical 
potential of the mineral species. This behavior inspired us to use chemical potentials during the 
acceptance test:
%
\begin{equation}
|\bar{\mu}_{e, i}-\mu_{e, i}^{\star}| 
\leq \epsilon_{{\rm rel}}|\mu_{e, i}^{\star}|+\epsilon_{{\rm abs}}
\qquad(i=1,\ldots,{\rm N}_e),
\label{eq:acceptance-test-mu}
\end{equation}
%
where $\bar{\mu}_{e, i}$ is the estimated chemical potential of the
$i$th species at the new chemical equilibrium state: 
\begin{equation}
\bar{\mu}_e = \mu^{\star}_e 
+ \frac{\partial\mu_e}{\partial T}^{\star}(T-T^{\star}) 
+ \frac{\partial\mu_e}{\partial P}^{\star}(P-P^{\star})
+ \frac{\partial\mu_e}{\partial n_e}^{\star}(n_e-n^{\star}_e),
\label{eq:mu-estimated}
\end{equation}
%
where $(\partial\mu_e/\partial T)^{\star}\in\mathbb{R}^{{\rm N}_e}$,
$(\partial\mu_e/\partial P)^{\star}\in\mathbb{R}^{{\rm N}_e}$, and 
$(\partial\mu_e/\partial n_e)^{\star}\in\mathbb{R}^{{\rm N_e\ensuremath{\times}N}_e}$
are chemical potential sensitivities evaluated at the equilibrium
state with input conditions $(T,P,b_e)^{\star}$. 

%---------------------------------------------------------------------------------------------------%
\textbf{Remark:} For the law of mass-action (LMA) methods, in which no access to standard chemical 
potentials exists in some cases (for example when the thermodynamic database used only contains 
equilibrium constants of reactions), a similar but \emph{not equivalent}, test exploits logarithm 
of activities:
%
\begin{equation}
|\ln\bar{a}_{i}-\ln a_{i}^{\star}| 
\leq \epsilon_{{\rm rel}} |\ln a_{i}^{\star}| + \epsilon_{{\rm abs}} 
\qquad(i=1,\ldots,{\rm N}_e).
\label{eq:acceptance-test-lna}
\end{equation}
%
%---------------------------------------------------------------------------------------------------%
Note, however, that activities are in general less sensitive to temperature variations than standard 
chemical potentials, so that the above alternative acceptance test would be less complete than  
Eq.~(\ref{eq:acceptance-test-mu}) and more indifferent towards temperature changes. To fix this, 
one could use the approach detailed in \citet{Leal2016b} that permits apparent standard chemical 
potentials of the species to be calculated using equilibrium constants of reactions.

%---------------------------------------------------------------------------------------------------%
To predicted amounts of the kinetic species, we control the variation in the kinetic rates, i.e., 
%
\begin{equation}
|\bar{r}_i - r^{\star}_i | 
\leq \epsilon_{{\rm rel}} | r_{i}^{\star}| + \epsilon_{{\rm abs}} 
\qquad (i=1,\ldots,{\rm N_k}),
\label{eq:acceptance-test-rates}
\end{equation}
%
where $\bar{r}_i - r^{\star}_i = {\tfrac{\partial r_i}{\partial n}}^\star (n - n^\star)
= {\tfrac{\partial r_i}{\partial n}}^\star
\begin{bmatrix} 
n_{e} - n^\star_e \\ 
n_{k} - n^\star_k 
\end{bmatrix}$.


%---------------------------------------------------------------------------------------------------%
\subsection{Smart Chemical Equilibrium / Kinetics Algorithm \label{subsec:Smart-chemical-algorithm}}

\begin{figure}
\begin{centering}
\includegraphics{figures/method/algorithm-flowchart-for-equilibrium}
\par\end{centering}
\caption{\label{fig:algorithm-diagram-equilibrium}
Diagram of the smart chemical equilibrium algorithm.}
\end{figure}

\begin{figure}
\begin{centering}
\includegraphics{figures/method/algorithm-flowchart-for-kinetics}
\par\end{centering}
\caption{\label{fig:algorithm-diagram-kinetics}
Diagram of the smart chemical kinetics algorithm.}
\end{figure}

%---------------------------------------------------------------------------------------------------%
The smart chemical equilibrium / kinetics algorithm proposed here is capable of remembering past 
chemical speciation calculations with corresponding sensitivity derivatives, using them to quickly 
and accurately estimate new equilibrium / kinetics states. 
%
The flowchart in Figure~\ref{fig:algorithm-diagram-equilibrium} illustrates the main steps of the 
algorithm focused on equilibrium species. At a very beginning, it solves the GEM problem 
Eq.~(\ref{eq:gem-problem}), which is represented by the computationally expensive equilibrium 
function~$\varphi$ Eq.~(\ref{eq:equilibrium-func}). Once this is done, the following information is 
saved for future fast and accurate predictions of equilibrium states, where the input conditions are 
relatively close to the one just recorded (i.e., learned):
%
\begin{itemize}
\item input conditions $(T, P, b_e)$;
\item corresponding calculated equilibrium amounts of species $n$;
\item sensitivity derivatives of the calculated equilibrium state: 
$\partial\varphi/\partial T$, $\partial\varphi/\partial P$, and $\partial\varphi/\partial b_e$;
\item derivatives of the chemical potentials 
$\partial\mu/\partial T$, $\partial\mu/\partial P$, and $\partial\mu/\partial n_e$.
\end{itemize}
%
See \citet{Leal2017} for a description of how to accurately calculate
these sensitivity and thermodynamic property derivatives.

%---------------------------------------------------------------------------------------------------%
Next time, when the algorithm is asked to solve a new equilibrium problem, it first does so by 
searching for the closest $(T,P,b_e)^{\star}$ to the given $(T,P,b_e)$ among all saved equilibrium 
input conditions in $\mathcal{I}_e$. Once the search is concluded, the previously calculated
potentially suitable equilibrium state is used to estimate the new equilibrium state using 
Eq.~(\ref{eq:smart-estimate}).
%---------------------------------------------------------------------------------------------------%
Finally, it remains to check if the estimated equilibrium state is accurate enough, using the 
acceptance test defined by Eq.~(\ref{eq:acceptance-test-mu}). If the test succeeds, then the 
speciation calculation ends. Otherwise, a complete chemical equilibrium calculation at $(T,P,b)$ is 
performed using GEM algorithm $n_e=\varphi(T,P,b_e)$. It is followed by similar derivative evaluation 
operations, as presented above, when the smart equilibrium algorithm was invoked for the first time.

%---------------------------------------------------------------------------------------------------%
The smart algorithm for kinetically controlled reactions is presented with the flowchart in 
Figure~\ref{fig:algorithm-diagram-kinetics}. It begins with integrating the system of ODEs 
Eq.~(\ref{eq:kinetics}) for reconstruction of kinetic species. After that or simultaneously, 
the sensitivity derivatives $\tfrac{n_k}{n^\circ_k}$ are calculated. Once this information is 
collected, it is saved for future fast and accurate predictions of kinetic states, where the input 
conditions are relatively close to the one just stored (i.e., learned):
%
\begin{itemize}
\item input conditions $n^\circ_k$;
\item corresponding calculated kinetics amounts of species $n_k$;
\item sensitivity derivatives of the calculated kinetic state $\tfrac{n_k}{n^\circ_k}$;
\item properties of the corresponding chemical state, such as chemical rates $r$ and the composition 
of equilibrium species $n_e$.
\end{itemize}
%---------------------------------------------------------------------------------------------------%
Next time, when the algorithm needs to solve a new kinetic path, it first retrieves the closest 
$(n^\circ_k)^\star$ to the given $n^\circ_k$ among all saved kinetic initial conditions in 
$\mathcal{I}_k$. Next, the previously calculated potentially suitable kinetic state $n_k$ is used as 
a reference to estimate the new kinetic state using Eq.~(\ref{eq:smart-estimate-kinetics}).
At the end, it remains to control whether the estimated kinetic state $\bar{n}_k$ satisfies the 
variational acceptance criterion defined by Eq.~(\ref{eq:acceptance-test-rates}). If this inequality 
is satisfied, then the calculation ends. Otherwise, a complete numerical integration with initial 
state $n^\circ_k$ is performed using the system Eq. \ref{eq:kinetics}. It is followed by the
evaluation of sensitivities, as discussed above, when the smart equilibrium algorithm was invoked 
for the first time.

%---------------------------------------------------------------------------------------------------%
\section{Results\label{sec:Results}}

We present here an example of using the smart chemical equilibrium / kinetics algorithm in a 
reactive transport simulation and show how its performance and precision compare to the use of a 
conventional chemical equilibrium / kinetics algorithms, based on either the Gibbs energy 
minimization for equilibrium species \citep{Leal2016a,Leal2017} or numerical integration for 
kinetically controlled ones. Moreover, we demonstrate the results of coupling Reaktoro to an 
open-source finite element library Firedrake that is used to model transport after the splitting of 
reactive transport equation. For details on how we solve the reactive transport equations, see 
Appendix~\ref{sec:Reactive-Transport-Equations}.

\subsection{Reactive Transport Problem\label{subsec:Reactive-Transport-Problem}}

%---------------------------------------------------------------------------------------------------%
The reactive transport modeling example carried out in this work is illustrated in 
Figure~\ref{fig:illustration-reactive-transport-model}. Here, the initial mineral composition of 
the horizontal porous rock column consists of 98\%$_{{\rm vol}}$ SiO$_{2}$(quartz) and 
2\%$_{{\rm vol}}$ CaCO$_{3}$(calcite), with an initial porosity of 10\% ($\phi = 0.1$). The resident 
fluid is a 0.70~molal~NaCl brine in equilibrium with the rock minerals (our calculated equilibrium 
state indicates a pH of about 9.2). The aqueous fluid, injected on the left side of this rock column, 
is the result of mixing 1~kg of water with 0.90~moles of NaCl, 0.05~moles of MgCl$_{2}$,
0.01~moles of CaCl$_{2}$, and 0.75~moles of CO$_{2}$. This amount of CO$_{2}$ is enough to bring 
the aqueous fluid close to CO$_{2}$ saturation at 100 bar, and thus in an acidic state, with a 
calculated pH of~3.05. The temperature and pressure of both resident and injected fluids
are 60~°C and 100~bar, respectively. The simplified reactive transport modeling assumes a constant 
fluid pore velocity (set in each cell) of $\boldsymbol{v}=\unit[1]{m/week}$ 
($\unit[5.95\cdot10^{-6}]{m/s}$) and the same diffusion coefficient $D=\unit[10^{-9}]{m^{2}/s}$ 
for all fluid species. The longitudinal dispersivity is estimated as $D \, \phi\,/\,\boldsymbol{v}$, 
which in this case is 100 times less than the usually accepted dispersivity of $10^{-3}$ m. 
Considered 1~m rock is discretized by the column mesh with 100~cells. The reactive transport 
simulation runs with 10`000 steps of uniform time step of 30~min, which results in 1'000'000 
chemical kinetics and equilibrium evaluations.
%

\begin{figure}
\begin{centering}
\includegraphics[width=1\textwidth]{figures/equilibrium/transport-scheme}
\par\end{centering}
\caption{\label{fig:illustration-reactive-transport-model}Illustration of
 reactive transport modeling along a one-dimensional rock core, including
some details on the injection fluid and rock composition, transport
parameters, and numerical discretization.}
\end{figure}


\subsection{Smart chemical equilibrium algorithm with the Pitzer activity model \label{subsec:part-1}}

%---------------------------------------------------------------------------------------------------%
In the chemical model part, the activity coefficients of the aqueous species are calculated using
the Pitzer model \citep{Pitzer1973}, formulated by \citet{Harvie1984}, except for the aqueous 
species CO$_{2}$(aq), for which the \citet{drummond1981boiling} model is applied. The standard 
chemical potentials of the species are calculated using the equations of state of 
\citet{Helgeson1974,Helgeson1978,Tanger1988,Shock1988} and \citet{Shock1992}. The database file 
\texttt{slop98.dat,} from the software SUPCRT92 \citep{Johnson1992}, is used to obtain corresponding
parameters. The equation of state of \citet{Wagner2002} is chosen to compute the density of water and 
its temperature and pressure derivatives. These prerequisites yield the system of \emph{36~chemical 
species} with \emph{4~phases} and \emph{9~chemical elements}. First, we neglect the dissolution and 
precipitation kinetics of both calcite and dolomite minerals (i.e., the local equilibrium assumption 
is employed). This way, we aim to assess how accurate the smart chemical equilibrium predictions are 
when phase transitions occur (e.g., when calcite fully dissolves and when dolomite starts to 
precipitate). 
%
\begin{figure}
\begin{centering}
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/calcite-dolomite-1}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/calcite-dolomite-10}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/calcite-dolomite-2400}
\par\end{center}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/aqueous-species-1}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/aqueous-species-10}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/aqueous-species-2400}
\par\end{center}%
\end{minipage}
\par\end{centering}
\caption{\label{fig:calcite-dolomite}
%
The volume percent ($\%_{{\rm vol}}$) of the minerals calcite and dolomite along the horizontal 
rock core as well as the concentrations of selected aqueous species (molal) at three different times: 
30~minutes, 5~hours, and 50~days (after 1, 10, and 2400~time steps of 30~minutes each, respectively). 
The \emph{solid lines} correspond to the results of the reactive transport simulation provided by 
conventional chemical equilibrium calculations based on full Gibbs energy minimization calculations 
performed in every cell of each time step. The circles ${\rm (}\bullet{\rm )}$ and 
${\rm (}\circ{\rm )}$ correspond to the values generated by the smart chemical equilibrium 
calculations. \emph{Solid circles} ${\rm (}\bullet{\rm )}$ indicate those cells, where successful
fast and accurate smart equilibrium predictions were preformed successfully. The 
\emph{empty circles} ${\rm (}\circ{\rm )}$ depict the cells, where full Gibbs energy minimization 
calculations were required and where, thus, \emph{on-demand learning} occurred.}
\end{figure}
%---------------------------------------------------------------------------------------------------%

\subsubsection{Smart Prediction Analysis \label{subsec:Performance-and-Accuracy}}
%
Figure~\ref{fig:calcite-dolomite} demonstrates the accuracy of the smart algorithm by comparing its 
results to the reference values generated by the conventional approach. In particular, it depicts the 
volume of minerals calcite, CaCO$_{3}$, and dolomite, CaMg(CO$_{3}$)$_{2}$ (left), as well as 
the concentrations of aqueous species Ca$^{2+}$(aq), Mg$^{2+}$(aq), HCO$_{3}^{-}$(aq), CO$_{2}$(aq), 
and H$^{+}$(aq) (right) along the horizontal rock column at three different simulation times: 
30~minutes, 5~hours, and 50~days. As calcite dissolves, Ca$^{2+}$(aq) ions are released into 
the aqueous solution, then reacting with the incoming Mg$^{2+}$(aq) ions from the left boundary 
to precipitate dolomite. After 30~minutes of injecting the CO$_{2}$-saturated brine (i.e., after a 
single time step), one observes a slight dissolution of calcite and corresponding precipitation of 
dolomite. 
%
The injected CO$_{2}$-saturated brine increases the local concentrations of carbolic species, 
CO$_{2}$(aq) and HCO$_{3}^{-}$(aq). The local concentrations of ions Ca$^{2+}$(aq) increases as a 
result of CaCO$_{3}$ dissolution. The precipitated dolomite, however, is gradually dissolved, as 
the injection of the acidic CO$_{2}$-saturated fluid continues. This can be seen in 
Figure~\ref{fig:calcite-dolomite} (bottom, left), in the very left region of the rock core, where 
neither calcite nor dolomite are present after 50~days of continuous fluid injection. At the same 
time, after 50~days of fluid injection (i.e., after 2400~time steps), the Mg$^{2+}$(aq) concentration 
drops sharply between core distances 0.1~m and 0.2~m, which is exactly where dolomite is currently 
precipitating. Moreover, in the same region Ca$^{2+}$(aq) concentration locally jumps as calcite 
dissolves.
%---------------------------------------------------------------------------------------------------%

We observe in Figure~\ref{fig:calcite-dolomite} that the use of the smart chemical equilibrium 
algorithm \emph{does not} compromise accuracy during the simulation. In this figure, the solid 
circles ${\rm (}\bullet{\rm )}$ represent a successful smart prediction of an accurate equilibrium
state at that cell position and time step, whereas the empty circles ${\rm (}\circ{\rm )}$ represent 
a failed attempt in this respect. The latter happens because of the absence of a previously solved 
chemical equilibrium problem similar enough to the new one. The empty circles ${\rm (}\circ{\rm )}$ 
also denote cells at which an on-demand learning operation was triggered, resulting in GEM 
calculation (that would be done anyway if the smart equilibrium algorithm was not used). These 
on-demand learning operations are triggered in different mesh cells, either on the same or different 
time steps. We remark that the current implementation of the algorithm does not rely on any spatial 
or temporal information, although this could be explored for faster search operations in the future.
%---------------------------------------------------------------------------------------------------%

From Figure~\ref{fig:calcite-dolomite}, we also can see that during the first time step of 
the simulation (30~minutes), the smart equilibrium algorithm was able to accurately estimate the 
equilibrium states in most mesh cells (see the solid circles $\bullet$). In other words, the 
algorithm learned enough distinct chemical equilibrium problems on a few upstream cells (near
the left boundary), which then could be successfully used for quick and accurate estimates for the 
rest of the cells downstream. To be precise, injecting the reactive fluid inside the rock core 
promotes strong compositional changes in both resident fluid and rock minerals. Because
of this, during the first time step, the algorithm requires \emph{on-demand learning} in 6 cells next 
to the left boundary (see the empty circles $\circ$ in Figure~\ref{fig:calcite-dolomite}). As the 
perturbation fronts move down the rock core, additional learning is performed as needed to fulfil 
a given accuracy criterion; here $\epsilon_{{\rm rel}}=0.1$ and $\epsilon_{{\rm abs}}=10^{-8}$ are 
used in Eq.~(\ref{eq:acceptance-test-mu}). As seen in Figure~\ref{fig:calcite-dolomite} (after 5h, 
or 10~time steps), 2~cells required a full and expensive chemical equilibrium calculation to both 
ensure accuracy and enable on-demand learning. 
{\color{red}
We also point out that after curtain amount of the 
time steps, trainings that are expected to be triggered at the cells, where a change of phases is 
happening, are not occurring any more. The algorithm has already 
gathered enough information about the system on the first time steps (while dolomite 
just started its precipitation and calcite its dissolution) that it does not have to learn any more
further down the road .}
%---------------------------------------------------------------------------------------------------%

\begin{figure}[!th]
\begin{centering}
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/errors-calcite-dolomite-l1.pdf}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/errors-calcite-dolomite-l1-percent.pdf}
\par\end{center}
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/errors-aqueous-l1}
\par\end{center}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/equilibrium/errors-aqueous-l1-percent}
\par\end{center}%
\end{minipage}
\par\end{centering}
\caption{\label{fig:error}
Error between results provided by the smart algorithm and reference values provided 
by the conventional approach. The $\ell_1$-norm of the error in the Calcite and Dolomite (left) 
and in aqueous species (right).}
\end{figure}

%---------------------------------------------------------------------------------------------------%
The percentage of the error measured in $\ell_1$-norm is illustrated in Figure \ref{fig:error}. 
We see that the $\ell_1$-norm of the error in the Calcite and Dolomite lies in the range 
$[10^{-5}, 10^{-2}]$, whereas the error in aqueous species might get an order higher 
$[10^{-5}, 10^{-1}]$. It can be explain with a slight delay in the smart algorithm to reproduce sharp 
changes on ions concentration. This yields that the uncertainty in minerals' volumes is bounded by 
1~\%, whereas, the inaccuracy of the aqueous concentration reproduced by the on-demand learning might 
get up till 16~\% in several cells throughout simulation.

\begin{figure}[!ht]
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/equilibrium/on-demand-learning-countings} \\
\includegraphics[width=0.7\textwidth]{figures/equilibrium/on-demand-learning-total}
\par\end{centering}
\caption{\label{fig:number-training-1}
The number of \emph{on-demand learning} operations triggered by the smart chemical equilibrium 
algorithm w.r.t. to the reactive transport steps (on the top) and their accumulated number during 
the reactive transport simulation (on the bottom) using a column mesh with 100~cells. The simulation 
finished after 10'000 time steps and required thus the solution of 1'000'000 chemical equilibrium 
problems. Only 258 (or 0.03\%) of these were solved using GEM calculation; the majority (99.97\%) 
were quickly and accurately estimated with the smart chemical equilibrium algorithm.}
\end{figure}

%---------------------------------------------------------------------------------------------------%
Figure~\ref{fig:number-training-1} presents the number of on-demand learning operations occurring 
(on the top) and accumulated (on the bottom) during the reactive transport simulation. For the top 
subplot, note rather high total number growth on the initial time steps, where the smart chemical 
equilibrium algorithm is actively learning new chemical states. That corresponds to the bottom 
illustration, where for the first RT steps full Gibbs energy minimization calculations are needed 
to be performed in up to 6 cells out of 100 ones. 
%
This is the result of the incoming brine perturbing the fluid composition on the left side of the 
horizontal rock core. As time passes, the increment of total on-demand learning operations becomes 
very small, about 1~or 2~cells per time step. The latter can be observed on the top subplot in Figure~\ref{fig:number-training-1}). 
%
Eventually, the smart prediction algorithm becomes knowledgeable enough about the recurring 
equilibrium states in the simulation, so that it can quickly and accurately perform all subsequent
speciations without further learning, or with just a few occasional training acts. We remark that 
this result is specific to the reactive transport example investigated here. In a reactive transport 
problem with more heterogeneity, for example, one could expect somewhat more on-demand learning 
requirements. We plan to investigate this dependency in future work.

%---------------------------------------------------------------------------------------------------%
\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/equilibrium/computing-costs-with-ideal}
\par\end{centering}
\caption{\label{fig:computational-cost}
Comparison of the computing costs (CPU time in microseconds) of transport, conventional, smart 
chemical equilibrium calculations, and so-called \emph{zero-search-cost} smart equilibrium 
calculations during each time step of the reactive transport simulation. The cost of equilibrium 
calculations per time step is the sum of the individual costs in each mesh cell,  whereas the cost 
of transport calculations per time step is the time required when solving the discretized algebraic 
transport equations. The zero-search-cost smart equilibrium calculation is the costs of on-demand 
learning algorithm excluding the costs for NN search.}
\end{figure}

%---------------------------------------------------------------------------------------------------%
Figure~\ref{fig:computational-cost} compares the computational cost at each time step of: 
\emph{(i)} conventional chemical equilibrium calculations, 
\emph{(ii)} smart chemical equilibrium calculations (or zero-cost-search smart equilibrium 
calculations), and \emph{(iii)} transport calculations. 
%
These costs are measured as CPU time in microseconds. For the equilibrium calculations, conventional
and smart, we show CPU time needed to calculate all equilibrium states across all mesh cells within 
the same time step. For the transport calculations, the cost is the time needed to solve the 
algebraic transport equations (we use direct Thomas algorithm for tridiagonal linear systems). 
As the name suggests, zero-cost-search smart equilibrium calculations are the costs of 
on-demand learning algorithm per each time RT step excluding the costs for NN search.
%---------------------------------------------------------------------------------------------------%
Figure~\ref{fig:computational-cost} confirms that the cost of conventional chemical equilibrium 
calculations can be orders of magnitude higher than the cost of transport calculations (about five 
orders of magnitude higher in this relatively simple reactive transport example). The figure also shows 
that the computational cost associated with chemical equilibrium calculations is drastically reduced 
using the smart equilibrium algorithm (by about three orders of magnitude when smart predictions are 
made in all mesh cells during a time step). We note that during the first time steps of the RT 
simulation, the CPU time spent on the smart equilibrium algorithm has relatively high spikes
in comparison to that after 4000~time steps. We observe, for most of those spikes, that the need of 
on-demand learning existed only in 1~to 2~cells (out of 100). After about half of the simulation time, 
the orange curve exhibits only few peaks, which correspond to only occasional learning acts, demanded 
by the acceptance test of the algorithm. The red line, corresponding to the zero-cost-search smart 
equilibrium calculations, indicates potential improvement in the CPU time of the on-demand learning 
algorithm once the costs of the reference point retrieval will be improved. Below, we consider 
several strategies to address the performance of look-up operations for already evaluated chemical 
states.

\subsubsection{Nearest Neighbor Search Analysis\label{subsec:Nearest-Neighbor-Search-Analysis-Equilibrium}}

%---------------------------------------------------------------------------------------------------%
As mentioned above, estimating an equilibrium state in a smart chemical equilibrium calculation 
requires a retrieval operation for the reference chemical state, which can be used in Taylor expansion. 
Currently, this search is performed among all currently recorded fully solved chemical equilibrium
problems, during the ongoing reactive transport simulation. It is needed to find the previously 
solved equilibrium problem whose input conditions are the closest (in the sense of Euclidean norm) 
to the input conditions of the new problem. Thus, the computing cost of the search operation 
increases as we perform more on-demand learning calculations because, at the end of each of them, 
a newly learned equilibrium state is stored.

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/equilibrium/search-traylor-vs-total-learnings}
\par\end{centering}
\caption{\label{fig:search-traylor-vs-total-learnings}
%
The computing time for the total estimation, NN search operations, as more fully solved equilibrium 
problems are stored during the simulation. A comparison is made against the computing time required 
for the first-order Taylor expansion calculation, which is a small and fast matrix-vector 
multiplication with more or less constant cost throughout. }
\end{figure}

%---------------------------------------------------------------------------------------------------%
Figure~\ref{fig:search-traylor-vs-total-learnings} demonstrates this increase in search cost as more 
learned equilibrium problems are recorded during the reactive transport simulation (orange line). 
This time impacts directly to the general costs of the estimation step (green line). They are both 
compared to the cost of performing a first-order Taylor expansion calculation (a small and fast 
matrix-vector multiplication), which exhibits rather constant computing costs. This increase in 
search time eventually ceases and becomes constant, because the smart algorithm has already learned 
enough key chemical equilibrium problems to quickly estimate most (in some cases all) subsequent 
ones. 
%
However, should the problem contain more geologic and/or chemical complexity, this cost could 
continue to increase. This most certainly implies the importance of the use of the data structure 
(such as kd-tree or locally sensitive hashing tables) that would allow to maintain the costs of 
retrieval algorithm constant and amenable. 
%
In order to further improve search times, previously stored learned problems could also be ranked, 
so that those that have not had much use for quickly predicting new states are purged from the 
database eventually. The chemical state most often used for smart prediction will have higher rank
that can define their order during the retrieval step. As soon as such reference state provides as 
an accurate enough prediction, the search can be terminated and its costs would be optimized 
to remain negligible (compared to other costs in the simulation).

%---------------------------------------------------------------------------------------------------%
\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/equilibrium/speedups}
\par\end{centering}
\caption{\label{fig:speedup-with-and-without-search-costs}
The speedup factor of chemical equilibrium calculations, at each time step of the simulation, 
resulting from the use of the on-demand learning acceleration strategy, employing a linear NN search 
(orange). A comparison is made with the speedup obtained by removing the computing time needed for 
the retrieval of the reference state (blue). The latter indicates an upper bound for the speedup 
upon improvement of the search algorithm.}
\end{figure}

%---------------------------------------------------------------------------------------------------%
Let us consider the speedup at each time step of the reactive transport simulation, which is 
calculated as the ratio of the accumulated time needed for the conventional to the smart chemical 
equilibrium calculations across all cells in the mesh. It is depicted in Figure 
\ref{fig:search-traylor-vs-total-learnings} with an orange line. 
%
Considering a \emph{hypothetical ideal NN search algorithm}, whose computing cost is zero, we have 
shown that the search operations contribute most to the computation cost of the smart chemical 
equilibrium method. This is the case, as the Taylor extrapolation calculation is fast (see Figure 
\ref{fig:search-traylor-vs-total-learnings} discussed above). By excluding the costs of the NN 
search (which we also refer to as ideal or zero-cost NN search algorithm) should yield an 
approximation of the upper bound of the speedup we expect to obtain (see blue line in Figure~\ref{fig:speedup-with-and-without-search-costs}). The speedup of our current implementation 
of the smart chemical equilibrium algorithm stabilizes at a value close to 200, whereas the ideal 
speedup is about 400. Thus, further research and improvements in this regard are needed further 
acceleration of the algorithm. 

\subsection{Smart chemical kinetics algorithm with the HKF activity model \label{subsec:part-2}}


Next, let us consider the performance of the smart chemical kinetics algorithm.
%---------------------------------------------------------------------------------------------------%
The on-demand learning for chemical equilibrium algorithm, discussed in the details in Subsection 
\ref{subsec:part-1}, is heavily used in the simulations of kinetically controlled species. 
We clarify the steps of the ODML algorithm for chemical kinetics below for each RT step 
$[t_k, t_{k+1}], k = 1, \ldots {\rm K}$:
%
\begin{itemize} 
\setlength{\itemsep}{0pt} \setlength{\parskip}{0pt}
\item Transport generates $n^\circ = [n^\circ_k; n^\circ_e]$ for all cells.
\item For each cell: 
\begin{itemize}
\setlength{\itemsep}{0pt} \setlength{\parskip}{0pt}
\item Evolve kinetics species $n_k$ by smart kinetics algorithm (see Figure \ref{fig:kinetics-algorithm}) 
using either {on-demand learning / training / full system of ODEs integration} (which corresponds to 
empty circles {\large $\fullmoon$}) or {prediction / estimation} (filled circles {\large $\newmoon$}).
\item Update equilibrium species $n_e$.
\end{itemize}
%
\item Combine the species amounts $n = [n_k; n_e]$.
\end{itemize}

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/kinetics/algorithm.png}
\par\end{centering}
\caption{\label{fig:kinetics-algorithm}. 
The ODML algorithm for chemical kinetics on the reactive step $[t_k, t_{k+1}], k = 1, \ldots {\rm K}$.}
\end{figure}


%---------------------------------------------------------------------------------------------------%
In the chemical model part, the activity coefficients of the aqueous species are calculated using
the HKF model extended Debye-H\"uckel model \citep{Helgeson1974a, Helgeson1974, Helgeson1976, 
Helgeson1981} for solvent water and ionic species, except for the aqueous 
species CO$_{2}$(aq), for which the \citet{drummond1981boiling} model is applied. The rest of chemical
properties coincides with assumptions of Subsection \ref{subsec:part-1}. We assume dissolution kinetics 
calcite, whereas dolomite is precipitating in equilibrium (using local equilibrium assumption 
is employed). The considered reaction of calcite dissolution is 
%
$$\mbox{CaCO}_3(s) + {\rm H}^{+} \rightleftharpoons \mbox{Ca}^{2+} + \mbox{HCO}_3^{-}.$$
%
Rates of minerals' dissolution can be represented by the following function for the $m$th mineral
%
$$r_{m}(T,P,n):= \mathcal{A}_{m}(n)\sum^{\rm reactions}_{i} \mathcal{M}_{m,i}(T,P,n), 
\quad r_{m}:\mathbb{R}^{2+N} \rightarrow \ensuremath{\mathbb{R}},$$ where 
%
$\mathcal{A}_{m} := n_{m} \, \sigma_{m}$ is a \emph{surface area function} \big[$\mathrm{m^2}$\big] 
with \emph{current molar amount} of the mineral $n_{m}$ \big[$\mathrm{mol}$\big] 
and  \emph{current specific reactive surface area} $\sigma_{m}$ \big[$\mathrm{{m^2}/{mol}}$\big]. 
%
Here, 
$$\mathcal{M}_{m,i} 
:= k_{m,i} \, {\rm sgn}(1-\Omega) \, |1-\Omega^{p_{i}}|^{q_{i}} 
\,\prod_{j} a_{j}^{\xi_{j}} \prod_{g} P_{g}^{\eta_{g}}$$
%
is the \emph{$i$-th kinetic mechanism function} \big[$\tfrac{mol}{m^2 s}$\big], where 
$\Omega := {1}/{K_{m}}\prod_{i=1}^{N} \, a_{i}^{\nu_{i}}$ is current \emph{saturation index} 
defined via product of activities with power of \emph{stoichiometric coefficient} $\nu_{i}$ of 
the $i$-th ionic species and \emph{equilibrium constant} $K_{m}$. 
%
The $i$-th \emph{rate constant} (Arrhenius eq.) $k_{m,i}$ is defined as 
%
$$k_{m,i} := k_{m,i}^{\circ} \exp \Big[-\tfrac{E_{m,i}}{R}(\tfrac{1}{T}-\tfrac{1}{298.15})\Big],$$ 
%
where $k_{m,i}^{\circ}$ is the \emph{reaction rate} constant at 25$^\circ$ 
and $E_{m,i}$ is the \emph{activation energy}, and the \emph{universal gas} constant $R$. 
The latter parameters for Calcite are taken from \cite{Palandri2004}, i.e., 
%
for acidic mechanism, 
$\log k_{i}^{\circ} = -5.81 \mathrm{{mol}/{m^2\,s}}$, \;$E_i$ = 23.5 $\mathrm{{kJ}/{mol^4}}$, and 
for neutral mechanism, 
$\log k_{i}^{\circ} = -0.30 \mathrm{{mol}/{m^2\,s}}$, \;$E_i$ = 14.4 $\mathrm{{kJ}/{mol^4}}$, 
$a[H^+]$ = 1.0.
The specific surface area of calcite is set to be 5000~${\rm {cm^2}/{g}}$. 


\subsubsection{Smart Prediction Analysis
\label{subsec:Performance-and-Accuracy-Kinetics}}

%---------------------------------------------------------------------------------------------------%
%
\begin{figure}
\begin{centering}
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics/calcite-dolomite-1}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics/calcite-dolomite-10}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics/calcite-dolomite-5800}
\par\end{center}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics/aqueous-species-1}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics/aqueous-species-10}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics/aqueous-species-5800}
\par\end{center}%
\end{minipage}
\par\end{centering}
\caption{\label{fig:calcite-dolomite-kinetics}
The volume percent ($\%_{{\rm vol}}$) of minerals calcite and dolomite along the rock core as well as 
the concentrations of selected aqueous species (in molal) at three different times: 30 minutes, 
5 hours, and 120 days, 2 hours (after 1, 10, and 5800 time steps of 30 minutes each, respectively). 
The \emph{solid curves} correspond to results of the reactive transport simulation using conventional
chemical kinetics calculations based on the integration of the system of ODEs for kinetically 
controlled species and update of the equilibrium species by the Gibbs energy minimization.
The circles ${\rm (}\bullet{\rm )}$ and ${\rm (}\circ{\rm )}$ correspond to the results using smart 
chemical kinetics calculations. \emph{Solid circles} ${\rm (}\bullet{\rm )}$ indicate successful
fast and accurate smart kinetics prediction at that point, whereas the \emph{empty circles} 
${\rm (}\circ{\rm )}$ depict the cells where \emph{on-demand learning} was needed.}
\end{figure}
%---------------------------------------------------------------------------------------------------%

Figure~\ref{fig:calcite-dolomite-kinetics} 
shows the volume of minerals calcite,
CaCO$_{3}$, and dolomite, CaMg(CO$_{3}$)$_{2}$ (left), as well
as the concentrations of aqueous species Ca$^{2+}$(aq), Mg$^{2+}$(aq),
HCO$_{3}^{-}$(aq), CO$_{2}$(aq), and H$^{+}$(aq) (right) along
the rock core at three different simulation times: 30 minutes, 5 hours,
and 50 days. As calcite dissolves, Ca$^{2+}$(aq) ions are released
into the aqueous solution, which reacts with the incoming Mg$^{2+}$(aq)
ions from the left boundary to precipitate dolomite. After 30 minutes
of injecting the CO$_{2}$-saturated brine (i.e., after a single time
step), one observes a slight dissolution of calcite and corresponding
precipitation of dolomite. The injected CO$_{2}$-saturated brine
increases the local concentrations of carbonic species, CO$_{2}$(aq)
and HCO$_{3}^{-}$(aq). The local concentrations of ions Ca$^{2+}$(aq)
increases as a result of CaCO$_{3}$ dissolution. The precipitated
dolomite, however, is gradually dissolved, as the injection of the
acidic CO$_{2}$-saturated fluid continues. This can be seen in Figure~\ref{fig:calcite-dolomite-kinetics}
(bottom, left), in the very left region of the rock core, where neither
calcite nor dolomite are present after 50 days of continuous fluid
injection. At the same time, after 50 days of fluid injection (i.e.,
after 2400 time steps), the Mg$^{2+}$(aq) concentration drops sharply
between core distances 0.1~m and 0.2~m, which is exactly where dolomite
is currently precipitating. Moreover, in the same region Ca$^{2+}$(aq)
concentration locally jumps as calcite dissolves.

Observe in Figure~\ref{fig:calcite-dolomite-kinetics} that the use of the
smart chemical equilibrium algorithm \emph{does not} compromise accuracy
during the simulation. In this figure, the solid circles ${\rm (}\bullet{\rm )}$
represent a successful smart prediction of an accurate equilibrium
state at that cell position and time step, whereas the empty circles
${\rm (}\circ{\rm )}$ represent a failure in this respect. The
latter happens because of the absence of a previously solved chemical
equilibrium problem similar enough to the new one. The empty circles
${\rm (}\circ{\rm )}$ also denote cells at which an on-demand learning
operation was triggered, resulting in a Gibbs energy minimization
calculation (that would be needed anyway if the smart equilibrium
algorithm was not used). These on-demand learning operations are triggered
in different mesh cells, either on the same or different time steps.
We remark that the current implementation of the algorithm does not
rely on any spatial or temporal information, although this could be
explored for faster search operations in the future.

From Figure~\ref{fig:calcite-dolomite-kinetics}, we also can see that during
the first time step of the simulation (30 minutes) the smart equilibrium
algorithm was able to accurately estimate the equilibrium states in
most mesh cells (see the solid circles $\bullet$). It learned enough
distinct chemical equilibrium problems on a few upstream cells (near
the left boundary) which could be successfully used for quick and
accurate estimates for the rest of the cells downstream. To be precise,
injecting the reactive fluid inside the rock core promotes strong
compositional changes in both resident fluid and rock minerals. Because
of this, during the first time step, the algorithm requires \emph{on-demand
learning} in 6 cells next to the left boundary (see the empty circles
$\circ$ in Figure~\ref{fig:calcite-dolomite-kinetics}). As the perturbation
fronts move down the rock core, additional learning is performed as
needed to fulfil a given accuracy criterion; here $\epsilon_{{\rm rel}}=0.1$
and $\epsilon_{{\rm abs}}=10^{-8}$ are used in equation~(\ref{eq:acceptance-test-mu}).
As seen in Figure~\ref{fig:calcite-dolomite-kinetics} (after 5h, or 10 time
steps), 2 cells require a full and expensive chemical equilibrium
calculation for both accuracy and on-demand learning purposes.

\begin{figure}
\begin{centering}
\includegraphics[width=0.5\textwidth]{figures/kinetics/on-demand-learning-total}
\includegraphics[width=0.5\textwidth]{figures/kinetics/on-demand-learning-countings}
\par\end{centering}
\caption{\label{fig:number-training-kinetics}
The accumulated number of \emph{on-demand
learning} operations triggered by the smart chemical equilibrium algorithm
during the reactive transport simulation using a mesh with 100 cells.
The simulation finished after 10'000 time steps and required thus
the solution of 1'000'000 chemical equilibrium problems. Only ***
(or 0.03\%) of these were solved using the full Gibbs energy minimization
calculation; the majority (99.97\%) were quickly and accurately estimated
with the smart chemical equilibrium algorithm.}
\end{figure}

Figure~\ref{fig:number-training-kinetics} presents the number of on-demand
learning operations during the reactive transport simulation. Note
a steep growth on the initial time steps, where the smart chemical
equilibrium algorithm is very actively learning new equilibrium problems.
These are a result of the incoming brine perturbing the fluid composition
on the left side of the rock core. As time passes, the increment of
such on-demand learning operations becomes very small, about 1 or
2 cells per time step. Eventually, the smart prediction algorithm
becomes knowledgeable enough about the recurring equilibrium states
in the simulation that it can quickly and accurately perform all subsequent
equilibrium calculations without further learning or just some occasional
ones. We remark that this result is specific to the reactive transport
example investigated here. In a reactive transport problem with more
heterogeneous features, for example, one could expect more on-demand
learning operations. We plan to investigate this in future work.


\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/kinetics/computing-costs}
\par\end{centering}
\caption{\label{fig:computational-cost-kinetics}Comparison of the computing costs (CPU
time in microseconds) of transport, conventional, and smart chemical
equilibrium calculations during each time step of the reactive transport
simulation. The cost of equilibrium calculations per time step is
the sum of the individual costs in each mesh cell, whereas the cost
of transport calculations per time step is the time required when
solving the discretized algebraic transport equations.}
\end{figure}

Figure~\ref{fig:computational-cost-kinetics} compares the computational cost,
at each time step, of: \emph{(i)} conventional chemical equilibrium
calculations, \emph{(ii)} smart chemical equilibrium calculations,
and \emph{(iii)} transport calculations. These costs are measured
as CPU time in microseconds. For the equilibrium calculations, conventional
and smart, we show CPU time needed to calculate all equilibrium states
across all mesh cells within the same time step. For the transport
calculations, the cost is the time needed to solve the algebraic transport
equations (e.g., solving sparse linear systems). Figure~\ref{fig:computational-cost-kinetics}
confirms that the cost of conventional chemical equilibrium calculations
can be orders of magnitude higher than the cost of transport calculations
(five orders of magnitude higher in this relatively simple reactive
transport example). It also shows that the computational cost associated
with chemical equilibrium calculations is drastically reduced with
the smart equilibrium algorithm (by about three orders of magnitude
when smart predictions are made in all mesh cells during a time step).
Note that on the first time steps of the reactive transport simulation,
CPU cost of smart equilibrium algorithm has relatively high spikes
in comparison to those after 4000 time steps. We observe in most of
those spikes the need of on-demand learning in 1 to 2 cells (out of
100). After about half of the simulation time, the orange curve has
only sparse peaks, which corresponds to only occasional learnings
demanded by the acceptance test of the algorithm.

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/kinetics/speedups}
\par\end{centering}
\caption{\label{fig:speedup-with-and-without-search-costs-kinetics}
The speedup of chemical
equilibrium calculations, at each time step of the simulation, resulting
from the use of the on-demand learning acceleration strategy (orange).
A comparison is made with the speedup obtained by removing the computing
time needed for the nearest neighbor search (blue). The latter indicates
an upper-bound for the speedup as our search algorithm is improved.}
\end{figure}


\subsection{Nearest Neighbor Search Analysis\label{subsec:Nearest-Neighbor-Search-Analysis-Kinetics}}

Recall that estimating an equilibrium state in a smart chemical equilibrium
calculation requires a nearest neighbor search operation. This search
is performed among all currently recorded fully solved chemical equilibrium
problems, during the ongoing reactive transport simulation. It is
needed to find the previously solved equilibrium problem whose input
conditions are the closest (in the sense of Euclidean norm) to the
input conditions of the new problem. Thus, the computing cost of the
search operation increases as we perform more on-demand learning calculations
because, at the end of these, we store a newly learned equilibrium
state.

Figure~\ref{fig:search-traylor-vs-total-learnings-kinetics} demonstrates
this increase in search cost as more learned equilibrium problems
are recorded during the reactive transport simulation. It also compares
it with the cost of performing a first-order Taylor extrapolation
calculation (a small and fast matrix-vector multiplication), which
has a rather constant computing cost. This increase in search time
eventually ceases because the smart algorithm has already learned
enough key chemical equilibrium problems to quickly estimate most
(in some cases all) of the subsequent ones. However, should we have
more geologic and geochemical complexity in the simulation, this cost
could continue increasing. This most certainly implies the importance
of the switch from a linear search algorithm to a kd-tree-based nearest
neighbor search algorithm to maintain this cost constant and amenable.
Previously stored learned problems could be ranked so that those that
have not had much use for quickly predicting new states are removed
from the database. In this way the cost of the search will remain
negligible compared to other costs in the simulation.

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/equilibrium/search-traylor-vs-total-learnings}
\par\end{centering}
\caption{\label{fig:search-traylor-vs-total-learnings-kinetics}
The computing time for
the nearest neighbor search operations as more fully solved equilibrium
problems are stored during the simulation. A comparison is made against
the computing time required for the first-order Taylor extrapolation
calculation, which is a small and fast matrix-vector multiplication
with more or less constant cost throughout.}
\end{figure}

Consider a \emph{hypothetical ideal nearest neighbor search algorithm}
whose computing cost is zero. We have shown that search operations
contribute to most of the cost in the smart chemical equilibrium method
because the Taylor extrapolation calculation is fast. The use of such
ideal nearest neighbor search algorithm should then give us an approximation
for the upper bound in the speedup we could ever obtain. This is shown
in Figure~\ref{fig:speedup-with-and-without-search-costs-kinetics}, where
the speedup\footnote{The speedup at each time step of the reactive transport simulation
is calculated as the ratio of the accumulated time needed for the
conventional and smart chemical equilibrium calculations across all
cells in the mesh.} of our current implementation of the smart chemical equilibrium algorithm
stabilizes at a value close to 200, whereas the ideal speedup is about
400. Thus, further research and improvement in this regard is needed
for even higher efficiency. 


{\color{green}{UPDATE:

To study acceleration of the chemical kinetics, we consider Calcite as kinetics 
species. Specific surface area = 50. 

\begin{figure}
\begin{centering}
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics-sa-50/calcite-dolomite-10}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics-sa-50/calcite-dolomite-1000}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics-sa-50/calcite-dolomite-2400}
\par\end{center}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics-sa-50/aqueous-species-10}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics-sa-50/aqueous-species-1000}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/kinetics-sa-50/aqueous-species-2400}
\par\end{center}%
\end{minipage}
\par\end{centering}
\caption{\label{fig:calcite-dolomite-kinetics}The volume percent ($\%_{{\rm vol}}$)
of minerals calcite and dolomite along the rock core as well as the
concentrations of selected aqueous species (in molal) at three different
times: 30 minutes, 5 hours, and 50 days (after 1, 10, and 2400 time
steps of 30 minutes each, respectively). The \emph{solid curves} correspond
to results of the reactive transport simulation using conventional
chemical equilibrium calculations based on the Gibbs energy minimization.
The circles ${\rm (}\bullet{\rm )}$ and ${\rm (}\circ{\rm )}$
correspond to the results using smart chemical equilibrium calculations.
\emph{Solid circles} ${\rm (}\bullet{\rm )}$ indicate successful
fast and accurate smart equilibrium prediction at that point, whereas
the \emph{empty circles} ${\rm (}\circ{\rm )}$ depict the cells
where \emph{on-demand learning} was needed.}
\end{figure}


\subsubsection{Smart Prediction Analysis
\label{subsec:Performance-and-Accuracy-Kinetics}}

Figure~\ref{fig:calcite-dolomite-kinetics} 
shows the volume of minerals calcite,
CaCO$_{3}$, and dolomite, CaMg(CO$_{3}$)$_{2}$ (left), as well
as the concentrations of aqueous species Ca$^{2+}$(aq), Mg$^{2+}$(aq),
HCO$_{3}^{-}$(aq), CO$_{2}$(aq), and H$^{+}$(aq) (right) along
the rock core at three different simulation times: 30 minutes, 5 hours,
and 50 days. As calcite dissolves, Ca$^{2+}$(aq) ions are released
into the aqueous solution, which reacts with the incoming Mg$^{2+}$(aq)
ions from the left boundary to precipitate dolomite. After 30 minutes
of injecting the CO$_{2}$-saturated brine (i.e., after a single time
step), one observes a slight dissolution of calcite and corresponding
precipitation of dolomite. The injected CO$_{2}$-saturated brine
increases the local concentrations of carbonic species, CO$_{2}$(aq)
and HCO$_{3}^{-}$(aq). The local concentrations of ions Ca$^{2+}$(aq)
increases as a result of CaCO$_{3}$ dissolution. The precipitated
dolomite, however, is gradually dissolved, as the injection of the
acidic CO$_{2}$-saturated fluid continues. This can be seen in Figure~\ref{fig:calcite-dolomite-kinetics}
(bottom, left), in the very left region of the rock core, where neither
calcite nor dolomite are present after 50 days of continuous fluid
injection. At the same time, after 50 days of fluid injection (i.e.,
after 2400 time steps), the Mg$^{2+}$(aq) concentration drops sharply
between core distances 0.1~m and 0.2~m, which is exactly where dolomite
is currently precipitating. Moreover, in the same region Ca$^{2+}$(aq)
concentration locally jumps as calcite dissolves.

Observe in Figure~\ref{fig:calcite-dolomite-kinetics} that the use of the
smart chemical equilibrium algorithm \emph{does not} compromise accuracy
during the simulation. In this figure, the solid circles ${\rm (}\bullet{\rm )}$
represent a successful smart prediction of an accurate equilibrium
state at that cell position and time step, whereas the empty circles
${\rm (}\circ{\rm )}$ represent a failure in this respect. The
latter happens because of the absence of a previously solved chemical
equilibrium problem similar enough to the new one. The empty circles
${\rm (}\circ{\rm )}$ also denote cells at which an on-demand learning
operation was triggered, resulting in a Gibbs energy minimization
calculation (that would be needed anyway if the smart equilibrium
algorithm was not used). These on-demand learning operations are triggered
in different mesh cells, either on the same or different time steps.
We remark that the current implementation of the algorithm does not
rely on any spatial or temporal information, although this could be
explored for faster search operations in the future.

From Figure~\ref{fig:calcite-dolomite-kinetics}, we also can see that during
the first time step of the simulation (30 minutes) the smart equilibrium
algorithm was able to accurately estimate the equilibrium states in
most mesh cells (see the solid circles $\bullet$). It learned enough
distinct chemical equilibrium problems on a few upstream cells (near
the left boundary) which could be successfully used for quick and
accurate estimates for the rest of the cells downstream. To be precise,
injecting the reactive fluid inside the rock core promotes strong
compositional changes in both resident fluid and rock minerals. Because
of this, during the first time step, the algorithm requires \emph{on-demand
learning} in 6 cells next to the left boundary (see the empty circles
$\circ$ in Figure~\ref{fig:calcite-dolomite-kinetics}). As the perturbation
fronts move down the rock core, additional learning is performed as
needed to fulfil a given accuracy criterion; here $\epsilon_{{\rm rel}}=0.1$
and $\epsilon_{{\rm abs}}=10^{-8}$ are used in equation~(\ref{eq:acceptance-test-mu}).
As seen in Figure~\ref{fig:calcite-dolomite-kinetics} (after 5h, or 10 time
steps), 2 cells require a full and expensive chemical equilibrium
calculation for both accuracy and on-demand learning purposes.

\begin{figure}
\begin{centering}
\includegraphics[width=0.5\textwidth]{figures/kinetics-sa-50/on-demand-learning-total}
\includegraphics[width=0.5\textwidth]{figures/kinetics-sa-50/on-demand-learning-countings}
\par\end{centering}
\caption{\label{fig:number-training-kinetics}
%
The accumulated number of \emph{on-demand
learning} operations triggered by the smart chemical equilibrium algorithm
during the reactive transport simulation using a mesh with 100 cells.
The simulation finished after 10'000 time steps and required thus
the solution of 1'000'000 chemical equilibrium problems. Only ***
(or 0.03\%) of these were solved using the full Gibbs energy minimization
calculation; the majority (99.97\%) were quickly and accurately estimated
with the smart chemical equilibrium algorithm.}
\end{figure}

Figure~\ref{fig:number-training-kinetics} presents the number of on-demand
learning operations during the reactive transport simulation. Note
a steep growth on the initial time steps, where the smart chemical
equilibrium algorithm is very actively learning new equilibrium problems.
These are a result of the incoming brine perturbing the fluid composition
on the left side of the rock core. As time passes, the increment of
such on-demand learning operations becomes very small, about 1 or
2 cells per time step. Eventually, the smart prediction algorithm
becomes knowledgeable enough about the recurring equilibrium states
in the simulation that it can quickly and accurately perform all subsequent
equilibrium calculations without further learning or just some occasional
ones. We remark that this result is specific to the reactive transport
example investigated here. In a reactive transport problem with more
heterogeneous features, for example, one could expect more on-demand
learning operations. We plan to investigate this in future work.


\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/kinetics-sa-50/computing-costs}
\par\end{centering}
\caption{\label{fig:computational-cost-kinetics}Comparison of the computing costs (CPU
time in microseconds) of transport, conventional, and smart chemical
equilibrium calculations during each time step of the reactive transport
simulation. The cost of equilibrium calculations per time step is
the sum of the individual costs in each mesh cell, whereas the cost
of transport calculations per time step is the time required when
solving the discretized algebraic transport equations.}
\end{figure}

Figure~\ref{fig:computational-cost-kinetics} compares the computational cost,
at each time step, of: \emph{(i)} conventional chemical equilibrium
calculations, \emph{(ii)} smart chemical equilibrium calculations,
and \emph{(iii)} transport calculations. These costs are measured
as CPU time in microseconds. For the equilibrium calculations, conventional
and smart, we show CPU time needed to calculate all equilibrium states
across all mesh cells within the same time step. For the transport
calculations, the cost is the time needed to solve the algebraic transport
equations (e.g., solving sparse linear systems). Figure~\ref{fig:computational-cost-kinetics}
confirms that the cost of conventional chemical equilibrium calculations
can be orders of magnitude higher than the cost of transport calculations
(five orders of magnitude higher in this relatively simple reactive
transport example). It also shows that the computational cost associated
with chemical equilibrium calculations is drastically reduced with
the smart equilibrium algorithm (by about three orders of magnitude
when smart predictions are made in all mesh cells during a time step).
Note that on the first time steps of the reactive transport simulation,
CPU cost of smart equilibrium algorithm has relatively high spikes
in comparison to those after 4000 time steps. We observe in most of
those spikes the need of on-demand learning in 1 to 2 cells (out of
100). After about half of the simulation time, the orange curve has
only sparse peaks, which corresponds to only occasional learnings
demanded by the acceptance test of the algorithm.

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/kinetics-sa-50/speedups}
\par\end{centering}
\caption{\label{fig:speedup-with-and-without-search-costs-kinetics}
The speedup of chemical
equilibrium calculations, at each time step of the simulation, resulting
from the use of the on-demand learning acceleration strategy (orange).
A comparison is made with the speedup obtained by removing the computing
time needed for the nearest neighbor search (blue). The latter indicates
an upper-bound for the speedup as our search algorithm is improved.}
\end{figure}


\subsection{Nearest Neighbor Search Analysis\label{subsec:Nearest-Neighbor-Search-Analysis-Kinetics-Sa-50}}

Recall that estimating an equilibrium state in a smart chemical equilibrium
calculation requires a nearest neighbor search operation. This search
is performed among all currently recorded fully solved chemical equilibrium
problems, during the ongoing reactive transport simulation. It is
needed to find the previously solved equilibrium problem whose input
conditions are the closest (in the sense of Euclidean norm) to the
input conditions of the new problem. Thus, the computing cost of the
search operation increases as we perform more on-demand learning calculations
because, at the end of these, we store a newly learned equilibrium
state.

Figure~\ref{fig:search-traylor-vs-total-learnings-kinetics} demonstrates
this increase in search cost as more learned equilibrium problems
are recorded during the reactive transport simulation. It also compares
it with the cost of performing a first-order Taylor extrapolation
calculation (a small and fast matrix-vector multiplication), which
has a rather constant computing cost. This increase in search time
eventually ceases because the smart algorithm has already learned
enough key chemical equilibrium problems to quickly estimate most
(in some cases all) of the subsequent ones. However, should we have
more geologic and geochemical complexity in the simulation, this cost
could continue increasing. This most certainly implies the importance
of the switch from a linear search algorithm to a kd-tree-based nearest
neighbor search algorithm to maintain this cost constant and amenable.
Previously stored learned problems could be ranked so that those that
have not had much use for quickly predicting new states are removed
from the database. In this way the cost of the search will remain
negligible compared to other costs in the simulation.

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/equilibrium/search-traylor-vs-total-learnings}
\par\end{centering}
\caption{\label{fig:search-traylor-vs-total-learnings-kinetics}
The computing time for
the nearest neighbor search operations as more fully solved equilibrium
problems are stored during the simulation. A comparison is made against
the computing time required for the first-order Taylor extrapolation
calculation, which is a small and fast matrix-vector multiplication
with more or less constant cost throughout.}
\end{figure}

Consider a \emph{hypothetical ideal nearest neighbor search algorithm}
whose computing cost is zero. We have shown that search operations
contribute to most of the cost in the smart chemical equilibrium method
because the Taylor extrapolation calculation is fast. The use of such
ideal nearest neighbor search algorithm should then give us an approximation
for the upper bound in the speedup we could ever obtain. This is shown
in Figure~\ref{fig:speedup-with-and-without-search-costs-kinetics}, where
the speedup\footnote{The speedup at each time step of the reactive transport simulation
is calculated as the ratio of the accumulated time needed for the
conventional and smart chemical equilibrium calculations across all
cells in the mesh.} of our current implementation of the smart chemical equilibrium algorithm
stabilizes at a value close to 200, whereas the ideal speedup is about
400. Thus, further research and improvement in this regard is needed
for even higher efficiency. 
}
}

\subsection{Coupling of Reaktoro with Firedrake on two-dimensional reactive transport problem  \label{subsec:part-3}}

ROCK

Firedrake for solving the partial differential equations (advection, diffusion, Darcy equation, etc.)


%---------------------------------------------------------------------------------------------------%
Our intention in this proof-of-concept paper is to demonstrate the potential of the on-demand 
learning algorithm, which will be followed by more advanced demonstrations in future work
(e.g., more heterogeneous media, three-dimensional meshes, etc.).


\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/rock/minerals.png}
\par\end{centering}
\caption{\label{fig:rock-minerals}
Mineral composition of the porous rock changing as an acidic aqueous fluid is injected on the left boundary.}
\end{figure}

\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/rock/porosity.png}
\par\end{centering}
\caption{\label{fig:rock-porosity}
Porosity changes as rock minerals react with the acidic aqueous fluid injected on the left boundary.}
\end{figure}


\begin{figure}
\begin{centering}
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/rock/ca-ion.png}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/rock/magnesium-ion.png}
\par\end{center}
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\begin{center}
\includegraphics[width=1\textwidth]{figures/rock/hco3-ion.png}
\par\end{center}
\begin{center}
\includegraphics[width=1\textwidth]{figures/rock/co2-aq.png}
\par\end{center}
\end{minipage}
\par\end{centering}
\caption{\label{fig:rock-aqueous-species} }
\end{figure}

\begin{figure}[!t]
	\centering
	\subfloat[]{
	\includegraphics[height=6cm]{figures/rock/permiability.png}
	\label{fig:rock-permiability}}
	\quad
	\subfloat[]{
	\includegraphics[height=6cm]{figures/rock/darcy-velocity.png}
	\label{fig:similar-equilibrium}}
	\caption{.}
	\label{fig:rock-darcy-velocity}
\end{figure}



\section{Discussion and Conclusions\label{sec:Discussion-and-Conclusions}}

We suggest using a smart chemical equilibrium algorithm with on-demand learning
acceleration capabilities to substantially speedup reactive transport
simulations. For the specific problem investigated in this work, we
obtained a minimum speedup of 200~compared to the use of a conventional chemical
equilibrium algorithm. We note that this speedup may be specific to the
problem studied and the assumptions made about this particular chemical system.
Having said that, the system tested in this paper already consists of 36~species in 4~phases, with the
non-ideal thermodynamic behavior of the aqueous phase modeled using
the relatively expensive Pitzer activity model.

This substantial speedup is due to the capability of the smart chemical
equilibrium algorithm to learn from previous calculations during the reactive
transport simulation. This permits a quick and accurate prediction
of most subsequent speciation calculations with relatively similar input conditions (without
requiring iterative computations, such as when employing the Newton method).
The use of sensitivity derivatives is essential for this quick estimation.
These derivatives are calculated at the end of each on-demand learning operation,
using the automatic differentiation methods provided by \texttt{\href{http://autodiff.github.io}{autodiff}}
\citep{autodiff2018}. The estimation of new chemical speciation reactions is carried out by employing a
first-order Taylor expansion, using a previously learned (and stored) equilibrium
state as a reference point. This reference equilibrium state is searched
for by comparing the given input conditions for the new equilibrium
problem with the input conditions of previously solved problems in
the course of the reactive transport simulation (using the NN search).

We remark that the use of an on-demand learning strategy has advantages
compared to more common machine learning algorithms. In particular,
there is no need for an \emph{a priori training stage}, which can
impose many difficulties to modelers (who should not necessarily need
to understand how algorithms work, but rather what they can solve)
and interrupt their usual workflow. For modeling scenarios in which
it is not possible to have a reasonable insight in all possible geochemical
conditions that a chemical system may undergo during a simulation,
an a-priori training step can be challenging and compute-intensive. It can also require a comprehensive
training stage, generating extremely large amounts of data, most of which will likely never be needed. Moreover, a minimal change in modeling parameters
or configuration detail is enough to make that big data array obsolete
(e.g., a change of activity model, addition\slash removal of phases\slash species\slash reactions,
etc.), which can potentially compromise an exploratory modeling exercise
with many tested and analyzed setups. Last, but not the least, traditional,
statistics-based machine learning algorithms, applied to chemical
equilibrium calculations, neither understand the thermodynamic behavior
of stable phases nor can straightforwardly predict equilibrium
states that satisfy mass conservation of chemical elements and electric
charge.

We plan to assess the efficiency of the smart chemical equilibrium
algorithm under more complex geochemical and geological conditions.
This includes, for example, modeling radionuclide migration in nuclear
waste repositories, degradation processes in concrete, geothermal
energy systems, and carbon dioxide storage in geologic formations.
As future work, we also consider to further improve the NN search algorithm and the use of alternative acceptance criteria when
determining whether the estimated state has been determined accurately enough. Using
a similar on-demand learning strategy for speeding up chemical kinetics
calculations in reactive transport simulations is already underway.

This smart chemical equilibrium strategy with on-demand learning has been implemented in Reaktoro (\href{https://www.reaktoro.org}{reaktoro.org}), a unified
open-source framework for modeling chemically reactive systems.


\subsection{Plans}
%---------------------------------------------------------------------------------------------------%
A combination of tree-based and linear search algorithms is then needed. We can start with a linear 
search approach, since initially there are not many saved inputs of learned chemical equilibrium 
problems. Once a certain number of inputs have been saved, we construct a kd-tree. This approach 
should enable constructing more well-balanced kd-trees (i.e., trees, where sibling branches have a 
similar number of entries), and thus ensure faster search operations close to $\log_{2}(K)$ complexity.

Alternatively, \emph{locality-sensitive hashing}, the algorithm that hashes similar input items into 
the so-called ``buckets'' with high probability, can be considered. This technique can also be used 
for data clustering, since the space of stored $\mathcal{I}_e$ and $\mathcal{I}_k$ can be heavily 
clustered. This approach attempts to reduce the dimensional of $k$-dimensional data by providing 
low-dimensional representation of the latter while preserving relative distances between items.
%
\begin{comment}
TO CHECK:
https://github.com/simonemainardi/LSHash
https://github.com/salviati/slash
https://github.com/DBWangGroupUNSW/SRS
https://web.archive.org/web/20101203074412/http://www.vision.caltech.edu/malaa/software/research/image-search/
http://web.mit.edu/andoni/www/LSH/index.html
https://falconn-lib.org/
\end{comment}
%
We also plan to investigate retrieval of the reference states based on the ranking system, giving the 
higher priority of the most used chemical states to be considered first. This way, as soon as the acceptance 
element satisfies certain considered criterion, we can terminate the search process.  


\begin{comment}
Residual-based acceptance algorithm. 

Reactive flows are all types of fluid flows with chemical reactions occouring within the fluid phase, at the interphase between different fluid phases or at interphases to solids. Gasphase combustion phenomena are the most important application of reactive flow modelling, while homogeneous combustion (gas-liquid or gas-solid) is still a minor research field. Simulation of reactive flows is getting more and more important, since they offer a possibility to gain insight to processes having harsh conditions, e.g. high temperture and pressure combustion. Additionally,  optimization of existing processes can be performed by modeling studies following design-of-experiment (DOE) approaches. In this way, the effort and costs for prototypes and field test can be reduced to a minimum.

However, modelling reactive systems is numerically expensive since the non-linear reaction kinetics leads to stiff-ODE systems in the species and energy conservation equations. Special solution algorithms, capable of handling these stiff systems of equations, are required to solve the equations. The best known stiff ODE solvers are the SIBS and RADAU5 algorithm.

Strategies to reduce the numerical effort to solve reactive flows include chemistry tabulation. Chemistry tabulation basically means that the solution of the given inital value problem (initial compostion, temperature, pressure) is stored. Subsequently, if similar starting values occur, the stored results are retrived and interpolated according to the differences in the starting values. These tabulation strategies differ depending on the employed combustion model. Some tabulation methods construct the tabulation on a predefined grid in the composition space, while others construt the tables "in-situ" during simulation run time.


\end{comment}

\section*{Acknowledgments}

This research project is funded by the Swiss National Science Foundation,
the Werner Siemens Foundation, and Shell. We thank these organizations
for their financial support.

\bibliographystyle{apalike-order-by-citation}
\bibliography{library,library-svetlana}

\appendix

\section{Chemical Kinetics Equations \label{subsec:Chemical-kinetics-equations}}

%---------------------------------------------------------------------------------------------------%
The \textbf{principle of mass conservation} $\frac{dn}{dt}=q$ yields 
%
\[
\frac{db}{dt}=\frac{db_{e}}{dt}+\frac{db_{k}}{dt}=Aq=A_{e}q_{e}+A_{k}q_{k},
\label{eq:mass-concervation}
\]
%
i.e., the amounts of the elements in the system $b$ vary according to the amounts of elements 
entering/leaving the system as a result of the given inflow/outflow rates of chemical species $q$. 
%
At the same time, Eq. \ref{eq:kinetics} for kinetic species yields
%
\begin{align}
\frac{db_{k}}{dt} & =A_{k}\nu_{k}^{T}r+A_{k}q_{k}.
\label{eq:kinetics-with-b}
\end{align}
%
%---------------------------------------------------------------------------------------------------%
Combination of Eq. \ref{eq:mass-concervation} and \ref{q:kinetics-with-b} leads to
%
\[
\frac{db_{e}}{dt}=A_{e}q_{e}-A_{k}\nu_{k}^{T}r.
\]
%
Using the \emph{stoichiometric balance condition} $A\nu^{T}=A_{e}\nu_{e}^{T}r+A_{k}\nu_{k}^{T}r=0$, 
which can be rewritten as $-A_{k} \, \nu_{k}^{T} \, r = A_{e}  \, \nu_{e}^{T} \, r$, we arrive at
\[
\frac{db_{e}}{dt} = A_{e}q_{e}-A_{k}\nu_{k}^{T}r = A_{e}(q_{e}+\nu_{e}^{T}r).
\]
%
This means that the \emph{chemical state of a system} is govern by the following differential-algebraic 
problem
%
\[
\begin{cases}
\frac{dn_{k}}{dt}=\nu_{k}^{T}r+q_{k} & t>0\\
\frac{db_{e}}{dt}=A_{e}(q_{e}+\nu_{e}^{T}r) & t>0\\
n_{e}=\varphi(b_{e}) & t>0\\
n_{k}=n_{k}^{\circ} & t=0\\
n_{e}=n_{e}^{\circ} & t=0\\
b_{e}=A_{e}n_{e}^{\circ} & t=0
\end{cases},
\]
where $n=(n_{e}^{\circ},n_{k}^{\circ})$ is given initial condition.


Open system:
\begin{align*}
\frac{dn}{dt} & =\nu^{T}r+q & t>0,\\
n & =n^{\circ} & t=0,
\end{align*}
where $r_{m}=r_{m}(T,P,n,a)$ is nonlinear dependent from $n$
\begin{itemize}
\item $q\in R^{N}$is a \emph{vector of inflow rates},
\item $n\in R^{N}$is a\emph{ vector of composition} of the chemical system,
\item $a\in R^{N}$is \emph{species activities}.
\end{itemize}
System of non-linear ODEs due to the non-linear dependence of $r_{m}=r_{m}(T,P,n,a)$
from $n$.\\

\textbf{\textcolor{brown}{Rate laws}}\\
\textbf{\textcolor{brown}{}}\\
\textcolor{black}{General }\textbf{\textcolor{black}{rate law}}\textcolor{black}{{}
for crystal growth and mineral dissolution (allows to model several
kinetic mineral mechanisms such as acid, neutral, base, carbonate,
and so forth) / mineral dissolution and precipitation
\begin{align*}
r_{m}(T,P,n) & :=n_{m}\sigma_{m}\sum_{i}M_{m,i}(T,P,n),\\
M_{m,i}(T,P,n) & :={\rm sgn}(1-\Omega)k_{m,i}|1-\Omega^{p_{i}}|^{q_{i}}\prod_{j}a_{j}^{\xi_{j}}\prod_{g}P_{g}^{\eta_{g}},
\end{align*}
where}
\begin{itemize}
\item $n_{m}$ is the \emph{current molar amount} of the mineral, either
dissolving or precipitating;
\item $\sigma_{m}$ is current specific\emph{ reactive surface area} of
the mineral (m2 / mol);
\item \textcolor{black}{$\Omega:=\frac{1}{K_{m}}\prod_{i=1}^{N}a_{i}^{\nu_{i}}$
is current }\textcolor{black}{\emph{saturation index}}\textcolor{black}{{}
of the mineral defined via activity product (and }$\nu_{i}$\emph{
stoichiometric coefficient} of the $i$-th ionic species\textcolor{black}{)
and }\textcolor{black}{\emph{equilibrium constant}}\textcolor{black}{{}
$K_{m}$}
\item \textcolor{black}{$k_{m,i}$ is the }\textcolor{black}{\emph{rate
constant}}\textcolor{black}{{} of the $i$th mineral reaction,$k_{m,i}:=k_{m,i}^{\circ}\exp\bigg[-\frac{E_{m,i}}{R}(\frac{1}{T}-\frac{1}{298.15})\bigg]$
(Arrhenius equation) with $k_{m,i}^{\circ}$ as the }\textcolor{black}{\emph{reaction
rate}}\textcolor{black}{{} constant at 25 °C, the }\textcolor{black}{\emph{activation
energy}}\textcolor{black}{{} $E_{m,i}$; and the }\textcolor{black}{\emph{universal
gas constant }}\textcolor{black}{$R$;}
\item \textcolor{black}{$p_{i}$ and $q_{i}$ are }\textcolor{black}{\emph{empirical
exponents}}\textcolor{black}{{} used to fit the rate law and control
how saturation affects the mineral rate; and}
\item \textcolor{black}{$a_{j}$ is the }\textcolor{black}{\emph{activity}}\textcolor{black}{{}
of the $j$th species, $P_{g}$ is the }\textcolor{black}{\emph{partial
pressure}}\textcolor{black}{{} of the $g$th gaseous species; and}
\item \textcolor{black}{$\xi_{j}$and $\eta_{g}$ are the exponents of the
catalysts (>0) and inhibitors (<0).}
\end{itemize}
\textbf{\textcolor{brown}{Partial equilibrium}}\\
\textbf{\textcolor{brown}{}}\\
Partition to:
\begin{itemize}
\item \emph{slow / kinetics} reaction (corresponding kinetics species) 
\[
0\rightleftharpoons\sum_{i=1}^{N}\nu_{ij}^{k}\alpha_{i},j=1,...,M_{k}
\]
with$\boldsymbol{\nu}_{k}\mathbb{\in M}^{M_{k}\times N}$, which include
kinetic $\boldsymbol{\nu}_{kk}\mathbb{\in M}^{M_{k}\times N_{k}}$
and equilibrium species $\boldsymbol{\nu}_{ke}\mathbb{\in M}^{M_{k}\times N_{e}}$
\item \emph{fast / equilibrium} reaction (corresponding equilibrium species)
\end{itemize}
\textcolor{brown}{Question: Isn't stoichometry just for the reactions?}

Then,
\begin{itemize}
\item $n_{e}$ and $n_{k}$ are the vectors of the amounts of the equilibrium
and the kinetic species, respectively;
\item $b_{e}$ and $b_{k}$ are the vectors of the amounts of the elements
such that 
\[
n=\begin{bmatrix}n_{e}\\
n_{k}
\end{bmatrix}:\mathbb{R}^{N}\rightarrow\mathbb{R}^{N}
\]
\item $A_{e}$ and $A_{k}$ are matrices of the equilibrium and kinetic
species $A=\begin{bmatrix}A_{e}\,A_{k}\end{bmatrix}$and
\item $\nu_{e}$ and $\nu_{k}$ are matrices formed from the \textbf{columns}
of the stoichiometric matrix $\nu=\begin{bmatrix}\nu_{e}\,\nu_{k}\end{bmatrix}$
\end{itemize}
Dependence of $n_{e}$ from $b_{e}$ is prescribed by the chemical
equilibrium function $n_{e}=\varphi(b_{e}),\varphi:\mathbb{R}^{E}\rightarrow\mathbb{R}^{N}$
that encapsulates the specific algorithmic steps to solve the equilibrium
problem
\[
\varphi(b_{e}):={\rm argmin}_{n_{e}}G_{e}=n_{e}^{T}\mu_{e}\quad\mbox{subject to}\quad\begin{cases}
A_{e}n_{e} & =b_{e}\\
n_{e} & \geq0
\end{cases}.
\]

The amounts of the kinetic species, $n_{k}$
\begin{align*}
\frac{dn_{k}}{dt} & =\nu_{k}^{T}r+q_{k} & t>0,\\
n_{k} & =n_{k}^{\circ} & t=0,
\end{align*}
where
\begin{itemize}
\item $r$ are the \emph{rates} of the kinetically controlled reactions;
\item $q_{k}$ denotes the\emph{ vector of inflow/outflow} rates of the
kinetic species and
\item $n_{k}^{\circ}$ the \emph{initial amounts }of the kinetic species.
\end{itemize}

The \textbf{principle of mass conservation} yields (the amounts of
chemical elements and electrical charge in the system must satisfy
the conservation equation)
\[
\frac{dn}{dt}=q\quad\rightarrow\quad\frac{db}{dt}=\frac{db_{e}}{dt}+\frac{db_{k}}{dt}=Aq=A_{e}q_{e}+A_{k}q_{k}.
\]
The amounts of the elements in the system $b$ vary according to the
amounts of elements entering/leaving the system as a result of the
given inflow/outflow rates of chemical species $q$. At the same time,
for kinetic species
\begin{align*}
\frac{dn_{k}}{dt}=\nu_{k}^{T}r+q_{k}\rightarrow\quad\frac{db_{k}}{dt} & =A_{k}\nu_{k}^{T}r+A_{k}q_{k}.
\end{align*}
\\
Combination of those two leads to
\[
\frac{db_{e}}{dt}=A_{e}q_{e}-A_{k}\nu_{k}^{T}r.
\]
Alternatively, the \emph{stoichiometric balance condition $A\nu^{T}=0$
}yields\textcolor{black}{
\[
A\nu^{T}r=A_{e}\nu_{e}^{T}r+A_{k}\nu_{k}^{T}r=0\quad\rightarrow\quad-A_{k}\nu_{k}^{T}r=A_{e}\nu_{e}^{T}r,
\]
which can be used above}
\[
\frac{db_{e}}{dt}=A_{e}q_{e}-A_{k}\nu_{k}^{T}r=A_{e}(q_{e}+\nu_{e}^{T}r).
\]
The \emph{chemical state of a system} is govern by the following differential-algebraic
problem \\
\[
\begin{cases}
\frac{dn_{k}}{dt}=\nu_{k}^{T}r+q_{k} & t>0\\
\frac{db_{e}}{dt}=A_{e}(q_{e}+\nu_{e}^{T}r) & t>0\\
n_{e}=\varphi(b_{e}) & t>0\\
n_{k}=n_{k}^{\circ} & t=0\\
n_{e}=n_{e}^{\circ} & t=0\\
b_{e}=A_{e}n_{e}^{\circ} & t=0
\end{cases},
\]
where $n=(n_{e}^{\circ},n_{k}^{\circ})$ is given initial condition.\\
\\
\textbf{Chemical kinetics: Computational methods}\\
\textbf{}\\
System of ODEs\textbf{}\\
\begin{align*}
\frac{du}{dt} & =f(u) & t>0,\\
u & =u^{\circ} & t=0,
\end{align*}
where $u=\begin{bmatrix}b_{e}\\
n_{k}
\end{bmatrix}$, $f(u)=\begin{bmatrix}A_{e}(\nu_{e}^{T}r+q_{e})\\
\nu_{k}^{T}r+q_{k}
\end{bmatrix}$, and $u^{\circ}=\begin{bmatrix}A_{e}n_{e}^{\circ}\\
n_{k}^{\circ}
\end{bmatrix}.$

For BDF mehod, the Jacobian of $f(u)$ is required, since in by backward
Euler method we obtain 
\[
u^{k+1}=u^{k}+dtf(u^{k+1}),
\]
which is solved by the Newton method for nonlinear equation
\[
g(u)=u-u^{k}-dtf(u)=0.
\]
Newton methods for reads as: $u^{l+1}=u^{l}+\Delta u^{l},$where the
increment is reconstructed from $(I-dtJ^{l})\Delta u^{l}=-g^{l}$.

\section{Chemical Equilibrium Equations \label{subsec:Chemical-equilibrium-equations}}

The solution of the Gibbs energy minimization problem ~(\ref{eq:gem-problem})
needs to satisfy the following \emph{first-order optimality conditions,}
also known as \emph{Karush–Kuhn–Tucker (KKT) conditions}, for a local
minimum of the Gibbs energy function $G$ \citep{Nocedal1999,Fletcher2000}:
\begin{alignat}{2}
\mu-A^{T}y-z & =0,\\
An-b & =0,\\
n_{i}z_{i} & =0 & \qquad & (i=1,\ldots,{\rm N}),\\
n_{i} & \geq0 &  & (i=1,\ldots,{\rm N}),\\
z_{i} & \geq0 &  & (i=1,\ldots,{\rm N}),
\end{alignat}
where $y\in\mathbb{R}^{{\rm E}}$ and $z\in\mathbb{R}^{{\rm N}}$
are introduced \emph{Lagrange multipliers} that need to be solved
along with the specie's amounts ${n\in\mathbb{R}^{{\rm N}}}$. For
more details about these Lagrange multipliers and their interpretation
as well as for instructions on how to efficiently solve these equations,
see \citet{Leal2016a,Leal2017}.

The previous chemical equilibrium equations can be written in an \emph{extended
law of mass action} (xLMA) formulation as
\begin{alignat}{2}
\ln K-\nu(\ln a+\ln w) & =0,\\
An-b & =0,\\
n_{i}\ln w_{i} & =0 & \qquad & (i=1,\ldots,{\rm N}),\\
n_{i} & \geq0 &  & (i=1,\ldots,{\rm N}),\\
0<w_{i} & \leq1 &  & (i=1,\ldots,{\rm N}),
\end{alignat}
following the use of the extended law of mass action equations
\begin{equation}
K_{m}=\prod_{i=1}^{{\rm N}}(a_{i}w_{i})^{\nu_{mi}}.\label{eq:xlma-equations}
\end{equation}
It is associated with the M linearly independent chemical reactions
among the N chemical species in equilibrium: 
\begin{equation}
0\rightleftharpoons\sum_{i=1}^{{\rm N}}\nu_{mi}\alpha_{i}\qquad(m=1,\ldots,{\rm M}),
\end{equation}
where ${K\in\mathbb{R}^{{\rm M}}}$ is the vector of \emph{equilibrium
constants} of the reactions, with ${K_{m}=K_{m}(T,P)}$ denoting the
equilibrium constant of the $m$th reaction, and $\nu\in\mathbb{R}^{{\rm M\ensuremath{\times}N}}$
is the \emph{stoichiometric matrix} of these chemical reactions, with
$\nu_{mi}$ corresponding to the stoichiometric coefficient of the
$i$th species in the $m$th reaction. Conventionally,$\nu_{mi}$
is positive if the $i$th species is a product in the $m$th reaction,
and negative if it is a reactant. Moreover, ${w\in\mathbb{R}^{{\rm N}}}$
is the vector of \emph{species stability factors} that need to be
solved along with the specie's amounts ${n\in\mathbb{R}^{{\rm N}}}$.
These factors are introduced to ensure that the extended law of mass
action equations (\ref{eq:xlma-equations}) are valid even when some
species in their corresponding reactions are unstable at equilibrium
(i.e., when a species belongs to a phase that is absent from equilibrium).
When all species are stable at equilibrium, it follows that ${w_{i}=1}$
and the xLMA equations reduce to the conventional LMA equations:
\begin{equation}
K_{m}=\prod_{i=1}^{{\rm N}}a_{i}^{\nu_{mi}}.
\end{equation}
The number of linearly independent chemical reactions among the N
species in equilibrium is ${{\rm M}={\rm N}-{\rm C}}$, where ${{\rm C}={\rm rank}(A)}$,
and thus whenever the formula matrix $A$ is full rank, ${\rm C}={\rm E}$
and ${\rm M}={\rm N}-{\rm E}$. For more information on how to
solve these equations and how they are related to the conventional
law of mass action equations, see \citet{Leal2016c,Leal2017}.

\section{Reactive Transport Equations\label{sec:Reactive-Transport-Equations}}

Composition of each particle evolve according to the follwing set
of ODEs:

\begin{alignat*}{2}
\frac{\partial n_{i}}{\partial t} & =T(n_{i})+R(n_{i}) & \qquad & (i=1,\ldots,{\rm N}),
\end{alignat*}
where $T$ is the transport operator that consists of advection and
diffusion, $R$ is reaction operator. First order splitting method:
the solution advances from the time $t_{0}$ for a small time step
$\Delta t$ in the following order:
\begin{itemize}
\item solve transport equation, such that solution is denoted by $\overline{n}:$\\
\[
\begin{cases}
\frac{\partial n}{\partial t} & =T(n)\\
n(t_{0}) & =\boldsymbol{n_{0}}
\end{cases}
\]
\item from the initial condition $\overline{n}$, solve the reaction equation
to obtain $\tilde{n}$:
\[
\begin{cases}
\frac{\partial n}{\partial t} & =T(n)\\
n(t_{0}) & =\boldsymbol{\overline{n}}
\end{cases}
\]
\end{itemize}


The fundamental mass conservation equations for both fluid and solid
species are:
\begin{alignat}{2}
\frac{\partial n_{i}^{{\rm f}}}{\partial t}+\nabla\cdot(\boldsymbol{v}n_{i}^{{\rm f}}-D\nabla n_{i}^{{\rm f}}) & =r_{i}^{{\rm f}} & \qquad & (i=1,\ldots,{\rm N}^{{\rm f}}),\label{eq:cons-mass-fluid-species}\\
\frac{\partial n_{i}^{{\rm s}}}{\partial t} & =r_{i}^{{\rm s}} &  & (i=1,\ldots,{\rm N}^{{\rm s}}),\label{eq:cons-mass-solid-species}
\end{alignat}
where $n_{i}^{{\rm f}}$ and $n_{i}^{{\rm s}}$ are the \emph{bulk
concentration} of the $i$th fluid and solid species (in mol/m$^{3}$),
respectively; $\boldsymbol{v}$ is the fluid pore velocity (in m/s);
$D$ is the diffusion coefficient of the fluid species (in m$^{2}$/s);
$r_{i}^{{\rm f}}$ and $r_{i}^{{\rm s}}$ are the rates of production\slash consumption
of the $i$th fluid and solid species (in mol\slash s), respectively,
due to chemical reactions; and ${\rm N}^{{\rm f}}$ and ${\rm N}^{{\rm s}}$
are the numbers of fluid and solid species, respectively. Note that
the above equations assume a single fluid phase and common diffusion
coefficients for all fluid species.

By partitioning the species as fluid and solid species, the formula
matrix $A$ can be conveniently represented as:
\begin{equation}
A=\begin{bmatrix}A^{{\rm f}} & A^{{\rm s}}\end{bmatrix},
\end{equation}
where $A^{{\rm f}}$ and $A^{{\rm s}}$ are the formula matrices
of the fluid and solid partitions (i.e., the matrices constructed
from the columns of $A$ corresponding to fluid and solid species).
The concentrations of elements in both fluid and solid partitions
$b_{j}^{{\rm f}}$ and $b_{j}^{{\rm s}}$ can then be calculated
from the species concentrations in the same partition using: 
\begin{alignat}{2}
b_{j}^{{\rm f}} & =\sum_{i=1}^{{\rm N}^{{\rm f}}}A_{ji}^{{\rm f}}n_{i}^{{\rm f}} & \qquad & (j=1,\ldots,{\rm E})\\
\shortintertext{and}b_{j}^{{\rm s}} & =\sum_{i=1}^{{\rm N}^{{\rm s}}}A_{ji}^{{\rm s}}n_{i}^{{\rm s}} &  & (j=1,\ldots,{\rm E}).
\end{alignat}

Recall that the rates of production of the species $r_{i}^{{\rm f}}$
and $r_{i}^{{\rm s}}$ are exclusively due to chemical reactions.
Let $r_{i}$ denote the rate of production\slash consumption of the
$i$th species in the system (i.e., using global index, and not a
local index within the fluid or solid partition). From the mass conservation
condition for the elements (chemical elements and electrical charge),
it follows that:
\begin{equation}
\underset{\substack{{\rm rate of production}\\
{\rm  of element \ensuremath{j}}
}
}{\underbrace{\sum_{i=1}^{{\rm N}}A_{ji}r_{i}}}=\underset{\substack{{\rm rate of production}\\
{\rm  of element \ensuremath{j} in}\\
{\rm the fluid partition}
}
}{\underbrace{\sum_{i=1}^{{\rm N}^{{\rm f}}}A_{ji}^{{\rm f}}r_{i}^{{\rm f}}}}+\underset{\substack{{\rm rate of production}\\
{\rm  of element \ensuremath{j} in}\\
{\rm the solid partition}
}
}{\underbrace{\sum_{i=1}^{{\rm N}^{{\rm s}}}A_{ji}^{{\rm s}}r_{i}^{{\rm s}}}}=\quad0,
\end{equation}
which is the mathematical statement for the fact that \emph{elements
are neither created nor destroyed} during chemical reactions. We can
combine this result with equations (\ref{eq:cons-mass-fluid-species})
and (\ref{eq:cons-mass-solid-species}) to derive the following conservation
equations for the elements:
\begin{equation}
\frac{\partial b_{j}^{{\rm s}}}{\partial t}+\frac{\partial b_{j}^{{\rm f}}}{\partial t}+\nabla\cdot(\boldsymbol{v}b_{j}^{{\rm f}}-D\nabla b_{j}^{{\rm f}})=0\qquad(j=1,\ldots,{\rm E}).
\end{equation}

Assume that all species, fluid and solid, are in \emph{local chemical
equilibrium everywhere, at all times}. One can then perform \emph{operator
splitting steps} to solve the fundamental mass conservation equations
(\ref{eq:cons-mass-fluid-species}) and (\ref{eq:cons-mass-solid-species})
to calculate the concentrations of the species, $n_{i}$, over time.
Let $k$ denote the current \emph{time step} and $\Delta t$ the \emph{time
step length} used in the discretization of the time derivative terms.
The operator splitting steps at the $k$th time step are:
\begin{enumerate}[wide=0.0\parindent,label=\bf{Step \arabic*)}]
\item update the concentrations of the elements in the fluid partition
using:
\[
\frac{\tilde{b}_{j}^{{\rm f},k+1}-b_{j}^{{\rm f},k}}{\Delta t}+\nabla\cdot(\boldsymbol{v}\tilde{b}_{j}^{{\rm f},k+1}-D\nabla\tilde{b}_{j}^{{\rm f},k+1})=0\qquad(j=1,\ldots,{\rm E}),
\]
where $\tilde{b}_{j}^{{\rm f},k}$ is the known concentration of
the $j$th element at time step $k$ in the fluid partition and $\tilde{b}_{j}^{{\rm f},k+1}$
is its unknown concentration at the next time step. Note that an implicit
scheme is assumed.
\item update the total concentrations of the elements:
\begin{equation}
b_{j}^{k+1}=\tilde{b}_{j}^{{\rm f},k+1}+b_{j}^{{\rm s},k}.
\end{equation}
\item calculate the concentrations of the species, $n_{i}^{k+1}$, in each
mesh cell, using the full or smart chemical reaction algorithm. For
this, use the local temperature and pressure values together with
the \emph{updated local concentrations of elements}, $b_{j}^{k+1}$,
as inputs.
\end{enumerate}

\end{document}
